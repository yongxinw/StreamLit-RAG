import json
import os
import sys
from typing import Any, List, Optional, Type
import streamlit as st
from langchain.retrievers import ContextualCompressionRetriever

from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain.callbacks.manager import (
    AsyncCallbackManagerForToolRun,
    CallbackManagerForToolRun,
)
from langchain.embeddings.dashscope import DashScopeEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.pydantic_v1 import BaseModel, Field
from langchain.text_splitter import (
    CharacterTextSplitter,
    RecursiveCharacterTextSplitter,
)

# from langchain_core.tools import BaseTool
from langchain.tools import BaseTool, StructuredTool, tool
from langchain.tools.retriever import create_retriever_tool
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain_community.llms import Tongyi
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableBranch, RunnableLambda

from statics import REGISTRATION_STATUS

os.environ["DASHSCOPE_API_KEY"] = "sk-91ee79b5f5cd4838a3f1747b4ff0e850"

st.set_page_config(
    page_title="å¤§ä¼—äº‘å­¦æ™ºèƒ½å®¢æœå¹³å°",
    page_icon="ğŸ¦™",
    layout="centered",
    initial_sidebar_state="auto",
    menu_items=None,
)
st.title("å¤§ä¼—äº‘å­¦æ™ºèƒ½å®¢æœå¹³å°, powered by LangChain")
if "messages" not in st.session_state.keys():  # Initialize the chat messages history
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "æ¬¢è¿æ‚¨æ¥åˆ°å¤§ä¼—äº‘å­¦ï¼Œæˆ‘æ˜¯å¤§ä¼—äº‘å­¦çš„ä¸“å®¶åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å›ç­”å…³äºå¤§ä¼—äº‘å­¦çš„æ‰€æœ‰é—®é¢˜ã€‚",
        }
    ]

# Simple demo tool - a simple calculator
class SimpleCalculatorTool(BaseTool):
    """è®¡ç®—ä¸¤ä¸ªè¾“çš„ä¹˜ç§¯çš„ç®€å•è®¡ç®—å™¨"""

    name: str = "ç®€å•è®¡ç®—å™¨"
    description: str = (
        "ç”¨äºè®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜ç§¯ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç¬¬ä¸€ä¸ªæ•° first_numberã€ç¬¬äºŒä¸ªæ•° second_number "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        # print(type(params))
        params_dict = json.loads(params)
        return params_dict["first_number"] * params_dict["second_number"]


class RegistrationStatusTool(BaseTool):
    """æŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€"""

    name: str = "æ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·"
    description: str = (
        "ç”¨äºæŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_number "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        # print(type(params))
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        if "user_id_number" not in params_dict:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        try:
            int(params_dict["user_id_number"])
        except ValueError:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        input = params_dict["user_id_number"]
        if REGISTRATION_STATUS.get(input) is not None:
            status = REGISTRATION_STATUS.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str
        return "ç»æŸ¥è¯¢ï¼Œæ‚¨å°šæœªåœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šæ³¨å†Œ"


class UpdateUserRoleTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ›´æ–°ç”¨æˆ·è§’è‰²"""

    name: str = "ç”¨æˆ·è§’è‰²æ›´æ–°å·¥å…·"
    description: str = (
        "ç”¨äºæ›´æ–°ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„è§’è‰²ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·è§’è‰² user_role "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        if "user_role" not in params_dict:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        user_role = params_dict["user_role"]
        if user_role not in ["ä¸“æŠ€ä¸ªäºº", "ç”¨äººå•ä½", "ä¸»ç®¡éƒ¨é—¨", "ç»§ç»­æ•™è‚²æœºæ„"]:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        agent_executor.agent.runnable.get_prompts()[0].template = (

"""Your ONLY job is to use a tool to answer the following question.

You MUST use a tool to answer the question. 
Simply Answer "æŠ±æ­‰ï¼Œæ ¹æ®æˆ‘çš„æœç´¢ç»“æœï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜" if you don't know the answer.
DO NOT answer the question without using a tool.

Current user role is """ + user_role + """.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
        )
        return f"æ›´æ–°æ‚¨çš„ç”¨æˆ·è§’è‰²ä¸º{user_role}, è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨ï¼Ÿ"


class AskForUserRoleTool(BaseTool):
    """è¯¢é—®ç”¨æˆ·è§’è‰²"""

    name: str = "ç”¨æˆ·è§’è‰²è¯¢é—®å·¥å…·"
    description: str = "ç”¨äºè¯¢é—®ç”¨æˆ·çš„è§’è‰²ï¼Œæ— éœ€è¾“å…¥å‚æ•°"
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        return "è¯·é—®æ‚¨æ˜¯ä¸“æŠ€ä¸ªäººã€ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨ï¼Œè¿˜æ˜¯ç»§ç»­æ•™è‚²æœºæ„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚"

@st.cache_data
def create_retrieval_tool(
    markdown_path,
    tool_name,
    tool_description,
    chunk_size: int = 100,
    chunk_overlap: int = 30,
    separators: List[str] = None,
    search_kwargs: dict = None,
    return_retriever: bool = False,
    rerank: bool = False,
):
    # Load files
    loader = UnstructuredMarkdownLoader(markdown_path)
    docs = loader.load()
    print(docs)

    # Declare the embedding model
    embeddings = DashScopeEmbeddings(
        model="text-embedding-v2",
    )

    # Chunk the files
    # chunk_size = 100
    # chunk_overlap = 30

    if separators is not None:
        text_splitter = RecursiveCharacterTextSplitter(
            # text_splitter = CharacterTextSplitter(
            separators=["\n\n"],
            # separators=["\n\n", "\n"], is_separator_regex=True
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
        )
    else:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
        )
    documents = text_splitter.split_documents(docs)
    vector = FAISS.from_documents(documents, embeddings)
    # if "login_problems" in markdown_path:
    #     import ipdb

    #     ipdb.set_trace()
    # Create a retriever tool
    if search_kwargs is None:
        retriever = vector.as_retriever()
    else:
        retriever = vector.as_retriever(search_kwargs=search_kwargs)

    # if rerank:
    #     # compressor = CohereRerank()
    #     compressor = FlashrankRerank()
    #     retriever = ContextualCompressionRetriever(
    #         base_compressor=compressor, base_retriever=retriever
    #     )

    registration_tool = create_retriever_tool(
        retriever,
        name=tool_name,
        description=tool_description,
    )
    # import ipdb
    # ipdb.set_trace()
    if return_retriever:
        return registration_tool, retriever
    return registration_tool


# create registration retrievers
registration_tool = create_retrieval_tool(
    "./policies/registration/registration.md",
    "registration_engine",
    "æŸ¥è¯¢å¤§ä¼—äº‘å­¦å¹³å°æ³¨å†Œæµç¨‹ï¼Œæ¥å›ç­”å¦‚ä½•æ³¨å†Œçš„ç›¸å…³é—®é¢˜ï¼Œå¹¶è¿”å›ç»“æœ",
)

auditing_tool = create_retrieval_tool(
    "./policies/registration/auditing.md",
    "auditing_engine",
    "å›ç­”å…³äºæ³¨å†Œå®¡æ ¸çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šè´¦å·æ€ä¹ˆåœ¨å®¡æ ¸ï¼Ÿå¦‚ä½•æŸ¥è¯¢å®¡æ ¸çŠ¶æ€ï¼Ÿ",
)

withdrawal_tool = create_retrieval_tool(
    "./policies/registration/withdrawal_and_modification.md",
    "withdrawal_engine",
    "å›ç­”å…³äºå¦‚ä½•æ’¤å›ã€ä¿®æ”¹ã€é©³å›æ³¨å†Œçš„é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæ³¨å†Œåå¦‚ä½•æ’¤å›ï¼Ÿä¸“æŠ€ä¸ªäººèƒ½æ’¤å›å—ï¼Ÿæ€ä¹ˆæ’¤å›ä¸äº†ï¼Ÿ",
)

faq_personal_tool = create_retrieval_tool(
    "./policies/registration/professional_individual_reg_page_faq.md",
    "professional_individual_registration_faq_engine",
    "å›ç­”ä¸“æŠ€ä¸ªäººæ³¨å†Œé¡µé¢ç»†é¡¹ï¼Œä»¥åŠå¸¸è§é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šè¯ä»¶å·æç¤ºå·²å­˜åœ¨ï¼Œæ²¡æœ‰è‡ªå·±ä¸“ä¸šï¼Œå•ä½æ‰¾ä¸åˆ°ï¼Œæ²¡æœ‰å•ä½æ€ä¹ˆåŠï¼ŒèŒç§°ç³»åˆ—æ€ä¹ˆé€‰æ‹©",
)

# faq_employing_unit_tool = create_retrieval_tool(
#     "./policies/registration/employing_unit_reg_page_faq.md",
#     "employing_unit_registration_faq_engine",
#     "å›ç­”ç”¨äººå•ä½æ³¨å†Œé¡µé¢ç»†é¡¹ï¼Œä»¥åŠå¸¸è§é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šå•ä½æ€§è´¨å’Œçº§åˆ«æ€ä¹ˆé€‰ï¼Œå•ä½æ‰€å±è¡Œä¸šé€‰ä»€ä¹ˆï¼Œä¸»ç®¡éƒ¨é—¨æ€ä¹ˆé€‰/ä»€ä¹ˆæ„æ€ã€ä¸Šçº§å•ä½æ˜¯ä»€ä¹ˆæ„æ€/æ€ä¹ˆé€‰ï¼ŒåŒçº§äººç¤¾é€‰ä»€ä¹ˆï¼Œä¿¡æ¯é€‰é”™äº†æ€ä¹ˆåŠ",
# )

# faq_cont_edu_tool = create_retrieval_tool(
#     "./policies/registration/continuing_edu_inst_reg_page_faq.md",
#     "continuing_education_institute_registration_faq_engine",
#     "å›ç­”ç»§ç»­æ•™è‚²æœºæ„æ³¨å†Œé¡µé¢ç»†é¡¹ï¼Œä»¥åŠå¸¸è§é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæœºæ„çº§åˆ«æ€ä¹ˆé€‰ã€ä»€ä¹ˆæ„æ€ï¼Œè¡Œä¸šä¸»ç®¡éƒ¨é—¨æ˜¯ä»€ä¹ˆæ„æ€ã€æ€ä¹ˆé€‰ï¼ŒåŒçº§äººç¤¾éƒ¨é—¨æ€ä¹ˆé€‰/åŒçº§äººç¤¾å‘¢ï¼Œé€‰é”™äº†æ€ä¹ˆåŠ/é€‰çš„ä¸å¯¹ä¼šæœ‰ä»€ä¹ˆå½±å“",
# )

# cannot_register_tool = create_retrieval_tool(
#     "./policies/registration/cannot_register.md",
#     "cannot_register_engine",
#     "å›ç­”ç”¨æˆ·æ— æ³•æ³¨å†Œçš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæ³¨å†Œä¸äº†æ€ä¹ˆåŠï¼Œæ³¨å†Œä¸ä¸Šæ€ä¹ˆåŠï¼Œæ³¨å†Œä¸äº†ï¼Œæ— æ³•æ³¨å†Œï¼Œæ³¨å†Œä¿å­˜ä»¥åä»€ä¹ˆååº”ä¹Ÿæ²¡æœ‰ï¼Œæ³¨å†Œæ²¡ååº”",
#     search_kwargs={"k": 1},
# )

# login_problems_tool = create_retrieval_tool(
#     "./policies/registration/login_problems.md",
#     "login_problems_engine",
#     "å›ç­”ç”¨æˆ·ç™»å½•é—®é¢˜çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šç™»å½•ä¸äº†ã€æ— æ³•ç™»å½•ã€æ€ä¹ˆç™»å½•ä¸ä¸Š",
#     search_kwargs={"k": 1},
#     chunk_size=100,
#     separators=["\n\n"],
# )

# login_problems_detail_tool = create_retrieval_tool(
#     "./policies/registration/login_problems_details.md",
#     "login_problems_detail_engine",
#     "å›ç­”ç”¨æˆ·ç™»å½•é—®é¢˜çš„ç»†èŠ‚ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæ²¡æœ‰æ»‘å—ï¼Œæ‰¾ä¸åˆ°æ»‘å—ï¼Œç™»å½•ä¸ºä»€ä¹ˆæç¤ºéªŒè¯å¤±è´¥ï¼Œå“ªé‡Œæœ‰æ»‘å—ï¼Œå¯†ç é”™è¯¯ï¼Œå¿˜è®°å¯†ç ï¼Œè´¦å·ä¸å­˜åœ¨ï¼Œç™»å½•æ˜¾ç¤ºå®¡æ ¸ä¸­",
#     search_kwargs={"k": 1},
#     chunk_size=100,
#     separators=["\n\n"],
# )

# TODO: Add more here
# forgot_password_tool = create_retrieval_tool(
#     "./policies/registration/forgot_password.md",
#     "forgot_password_engine",
#     "å›ç­”ç”¨æˆ·å¿˜è®°å¯†ç çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šå¿˜è®°å¯†ç æ€ä¹ˆåŠï¼Œå¯†ç å¿˜è®°äº†ï¼Œæ‰¾å›å¯†ç ",
#     # search_kwargs={"k": 1},
#     # chunk_size=100,
#     # separators=["\n\n"]
# )

# create operation retrievers
individual_operation_tool = create_retrieval_tool(
    "./policies/operation/individual_operation.md",
    "individual_operation_engine",
    "å›ç­”ä¸“æŠ€ä¸ªäººå­¦æ—¶ã€å­¦æ—¶ç”³æŠ¥ã€ä¿®æ”¹å•ä½çš„ç³»ç»Ÿæ“ä½œç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæ€ä¹ˆå­¦æ—¶ç”³æŠ¥ï¼Œå¦‚ä½•æäº¤å­¦æ—¶ï¼Œä¸ºä»€ä¹ˆä¸èƒ½å­¦æ—¶ç”³æŠ¥ï¼Œå­¦æ—¶ç”³æŠ¥ä¿¡æ¯å¤©å¡«é”™äº†æ€ä¹ˆåŠï¼Œå­¦æ—¶ä¿¡æ¯å¡«å¥½åæ— æ³•ä¿å­˜ï¼Œæˆ‘æ€ä¹ˆä¸èƒ½å­¦æ—¶ç”³æŠ¥ã€æˆ‘çš„è´¦å·é‡Œæ€ä¹ˆæ²¡æœ‰å­¦æ—¶ç”³æŠ¥ï¼Œè¯ä¹¦å’Œå‘æ˜ä¸“åˆ©èƒ½ç”³æŠ¥ã€æŠµæ‰£å¤šå°‘å­¦æ—¶ã€‚å†å¦‚ï¼šæ€ä¹ˆä¿®æ”¹å•ä½ï¼Œä¿®æ”¹å•ä½çš„è¯ï¼Œç°åœ¨å•ä½èƒ½çŸ¥é“å—ï¼Œç°åœ¨å•ä½å®¡æ ¸å—ï¼Œå•ä½è°ƒè½¬æç¤ºæœ‰å¾…å®¡æ ¸ä¿¡æ¯ï¼Œä¸èƒ½ä¿®æ”¹å•ä½ï¼Œå•ä½è°ƒè½¬ä¿¡æ¯å¡«é”™æ€ä¹ˆåŠï¼Œæ€ä¹ˆåˆ é™¤äººå‘˜ï¼Œç¦»èŒçš„äººå‘˜æ€ä¹ˆåŠï¼Œæ€ä¹ˆè°ƒåˆ°ä¸´æ—¶å•ä½",
    # search_kwargs={"k": 5},
    chunk_size=100,
    separators=["\n\n"],
)

employing_unit_operation_tool = create_retrieval_tool(
    "./policies/operation/employing_unit_operation.md",
    "employing_unit_operation_engine",
    "å›ç­”ç”¨äººå•ä½å­¦æ—¶ç”³æŠ¥ã€æ³¨å†Œå®¡æ ¸ã€ä¿¡æ¯å˜æ›´ã€æ›´æ¢ç®¡ç†å‘˜ã€äººå‘˜ä¿¡æ¯æŸ¥è¯¢çš„ç³»ç»Ÿæ“ä½œç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šå•ä½æ€ä¹ˆå®¡æ ¸ï¼Œæ€ä¹ˆæŠŠäººå‘˜è°ƒå‡ºå•ä½ï¼Œäººå‘˜ç¦»èŒäº†æ€ä¹ˆè°ƒå‡ºå»ï¼Œå¦‚ä½•å®¡æ ¸äººå‘˜æäº¤çš„å­¦æ—¶ï¼Œå­¦æ—¶ç”³æŠ¥é”™äº†ï¼Œå•ä½ä¹Ÿå®¡æ ¸äº†æ€ä¹ˆåŠï¼Œæ€ä¹ˆé©³å›ï¼Œå­¦æ—¶ç”³æŠ¥é”™äº†ï¼Œå•ä½ä¹Ÿå®¡æ ¸äº†æ€ä¹ˆåŠï¼Œå•ä½åŸ¹è®­è®¡åˆ’ï¼Œæ€ä¹ˆæäº¤ã€å®¡æ ¸ï¼Œæ€ä¹ˆæ›´æ¢å•ä½è¶…çº§ç®¡ç†å‘˜ï¼Œå•ä½å¦‚ä½•å¢åŠ ç®¡ç†å‘˜ï¼Œå¦‚ä½•æŸ¥è¯¢å•ä½åä¸‹ä¸“æŠ€äººå‘˜ä¿¡æ¯",
    chunk_size=100,
    separators=["\n\n"],
)

supervisory_department_operation_tool = create_retrieval_tool(
    "./policies/operation/supervisory_department_operation.md",
    "supervisory_department_operation_engine",
    "å›ç­”ä¸»ç®¡éƒ¨é—¨æ³¨å†Œå®¡æ ¸ã€ä¿¡æ¯å˜æ›´ã€ç»§ç»­æ•™è‚²æœºæ„å®¡æ ¸ã€å•ä½è°ƒè½¬å®¡æ ¸ã€å­¦æ—¶ç”³æŠ¥å®¡æ ¸ã€äººå‘˜ä¿¡æ¯æŸ¥è¯¢çš„ç³»ç»Ÿæ“ä½œç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šå¦‚ä½•å®¡æ ¸å•ä½æˆ–ä¸ªäººæ³¨å†Œä¿¡æ¯ã€äººå‘˜æˆ–ç”¨äººå•ä½ä¿¡æ¯å˜æ›´å®¡æ ¸ã€å¦‚ä½•å®¡æ ¸ç»§æ•™æœºæ„ä¿¡æ¯ã€äººå‘˜è°ƒå…¥å’Œå•ä½è°ƒè½¬å®¡æ ¸æ“ä½œã€å¦‚ä½•å®¡æ ¸ä¸“æŠ€äººå‘˜çš„å­¦æ—¶ã€å­¦æ—¶æŠ¥é”™äº†ï¼Œæ€ä¹ˆé©³å›ã€å­¦æ—¶ç”³æŠ¥é”™äº†ï¼Œä¹Ÿå®¡æ ¸é€šè¿‡äº†ï¼Œè¿˜èƒ½é©³å›å—ã€å¦‚ä½•æŸ¥è¯¢ä¸»ç®¡éƒ¨é—¨ä¸‹é¢å•ä½æƒ…å†µ",
    chunk_size=100,
    separators=["\n\n"],
)


# Create Agent
model = Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3})
# model.model_name = "qwen-max"
# model.model_kwargs = {"temperature": 0.3}

tools = [
    # multiply,
    RegistrationStatusTool(),
    AskForUserRoleTool(),
    UpdateUserRoleTool(),
    registration_tool,
    auditing_tool,
    withdrawal_tool,
    faq_personal_tool,
    # faq_employing_unit_tool,
    # faq_cont_edu_tool,
    # cannot_register_tool,
    # login_problems_tool,
    # login_problems_detail_tool,
    # forgot_password_tool,
    individual_operation_tool,
    employing_unit_operation_tool,
    supervisory_department_operation_tool,
]

# DO NOT hallucinate!!! You MUST use a tool to collect information to answer the questions!!! ALWAYS use a tool to answer a question if possible. Otherwise, you MUST ask the user for more information.
prompt = hub.pull("hwchase17/react")
prompt.template = """Your ONLY job is to use a tool to answer the following question.

You MUST use a tool to answer the question. 
Simply Answer "æŠ±æ­‰ï¼Œæ ¹æ®æˆ‘çš„æœç´¢ç»“æœï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜" if you don't know the answer.
DO NOT answer the question without using a tool.

Current user role is unknown.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
    "chat_history",
]

memory = ConversationBufferMemory(memory_key="chat_history", input_key="input")
agent = create_react_agent(model, tools, prompt)
agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent, tools=tools, memory=memory, verbose=True, handle_parsing_errors=True
)


# create a router chain
class CheckUserRoleTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·è§’è‰²"""

    name: str = "æ£€æŸ¥ç”¨æˆ·è§’è‰²å·¥å…·"
    description: str = "ç”¨äºæ£€æŸ¥ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„è§’è‰²ï¼Œæ— éœ€è¾“å…¥å‚æ•° "
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:
        print(params)
        template = agent_executor.agent.runnable.get_prompts()[0].template.lower()
        # print(template)
        start_index = template.find("current user role is") + len(
            "current user role is"
        )
        end_index = template.find("\n", start_index)
        result = template[start_index:end_index].strip()
        return result


router_prompt = hub.pull("hwchase17/react")
router_prompt.template = """Your ONLY job is to determine the user role. DO NOT Answer the question.

You MUST use a tool to find out the user role.
DO NOT hallucinate!!!!

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you will not answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!


Question: {input}
Thought:{agent_scratchpad}
user role:
"""
router_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
]

router_tools = [CheckUserRoleTool()]

router_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    router_tools,
    router_prompt,
)
router_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=router_chain, tools=router_tools, verbose=True, handle_parsing_errors=True
)

user_role_prompt = hub.pull("hwchase17/react")
user_role_prompt.template = """Your ONLY job is to ask the user to provide their role information regardless of the input.

You MUST ALWAYS say: è¯·é—®æ‚¨æ˜¯ä¸“æŠ€ä¸ªäººã€ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨ï¼Œè¿˜æ˜¯ç»§ç»­æ•™è‚²æœºæ„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚
You MUST use a tool to update user role.
DO NOT hallucinate!!!!

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!


Question: {input}
Thought:{agent_scratchpad}
"""
user_role_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
]

user_role_tools = [UpdateUserRoleTool()]

user_role_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    user_role_tools,
    user_role_prompt,
)
user_role_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=user_role_chain, tools=user_role_tools, verbose=True, handle_parsing_errors=True
)


# general_chain = (
#     PromptTemplate.from_template(
#         """Respond to the following question:

# Question: {input}
# Answer:"""
#     )
#     | Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3})
# )


def route(info):
    print(info["topic"])
    if "unknown" in info["topic"]["output"].lower():
        return user_role_chain_executor
    return agent_executor

full_chain = {"topic": router_chain_executor, "input": lambda x: x["input"]} | RunnableLambda(route)

# update prompt with this: agent_executor.agent.runnable.get_prompts()[0]


if "chat_engine" not in st.session_state.keys():  # Initialize the chat engine
    # st.session_state.chat_engine = index.as_chat_engine(
    #     chat_mode="condense_question", verbose=True
    # )
    st.session_state.chat_engine = full_chain

if prompt := st.chat_input(
    "æ‚¨çš„é—®é¢˜"
):  # Prompt for user input and save to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    # st.session_state.chat_engine.memory.add_message(
    #     {"role": "user", "content": prompt}
    # )

for message in st.session_state.messages:  # Display the prior chat messages
    with st.chat_message(message["role"]):
        st.write(message["content"])

# If last message is not from assistant, generate a new response
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            # response = st.session_state.chat_engine.chat(prompt)
            # response = st.session_state.chat_engine.invoke({"input": prompt})
            response = st.session_state.chat_engine.invoke({"input": prompt})
            st.write(response["output"])
            message = {"role": "assistant", "content": response["output"]}
            # st.session_state.chat_engine.memory.add_message(message)
            st.session_state.messages.append(message)  # Add response to message history
