"""
TODO:
    0. refactor code.
    1. Chain not able to get back to the starting point if seleting a role in the beginning (explore lang-graph). 
    2. If similarity score is too low (asking irrellavant questions), answer can't answer.
    3. Add causual chatbot.
    4. Future data organization.
    5. Improve latency.
    6. Test general API for more data.
"""
from langchain.tools.render import render_text_description
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import (
    RunnableBranch,
    RunnableLambda,
    RunnableParallel,
    RunnablePassthrough,
)

from operator import itemgetter

import json
import os
import re
import sys
from typing import Any, List, Optional, Type

import streamlit as st
from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain.callbacks.manager import (
    AsyncCallbackManagerForToolRun,
    CallbackManagerForToolRun,
)
from langchain.chains import LLMChain
from langchain.embeddings.dashscope import DashScopeEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.pydantic_v1 import BaseModel, Field
from langchain.retrievers import ContextualCompressionRetriever
from langchain.text_splitter import (
    CharacterTextSplitter,
    RecursiveCharacterTextSplitter,
)

# from langchain_core.tools import BaseTool
from langchain.tools import BaseTool, StructuredTool, tool
from langchain.tools.retriever import create_retriever_tool
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain_community.llms import Tongyi
from langchain_community.vectorstores import FAISS
from langchain_core.documents.base import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableBranch, RunnableLambda

from statics import (
    COURSE_PURCHASES,
    CREDIT_HOURS,
    LOC_STR,
    REGISTRATION_STATUS,
    REGISTRATION_STATUS_NON_IDV,
)
from utils import (
    check_user_location,
    create_atomic_retriever_agent,
    create_atomic_retriever_agent_single_tool_qa_map,
    create_dummy_agent,
    create_react_agent_with_memory,
    create_single_function_call_agent,
    output_parser,
)

# from langchain_openai import ChatOpenAI, OpenAIEmbeddings


os.environ["DASHSCOPE_API_KEY"] = "sk-91ee79b5f5cd4838a3f1747b4ff0e850"
# os.environ["DASHSCOPE_API_KEY"] = "sk-c92ed98926194b84a41a73db62af31d5"
os.environ["OPENAI_API_KEY"] = "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"
st.set_page_config(
    page_title="å¤§ä¼—äº‘å­¦æ™ºèƒ½å®¢æœå¹³å°",
    page_icon="ğŸ¦™",
    layout="centered",
    initial_sidebar_state="auto",
    menu_items=None,
)
st.title("å¤§ä¼—äº‘å­¦æ™ºèƒ½å®¢æœå¹³å°, powered by LangChain")
if "messages" not in st.session_state.keys():  # Initialize the chat messages history
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": """æ¬¢è¿æ‚¨æ¥åˆ°å¤§ä¼—äº‘å­¦ï¼Œæˆ‘æ˜¯å¤§ä¼—äº‘å­¦çš„ä¸“å®¶åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å›ç­”å…³äºå¤§ä¼—äº‘å­¦çš„æ‰€æœ‰é—®é¢˜ã€‚æµ‹è¯•è¯·ä½¿ç”¨èº«ä»½è¯å·372323199509260348ã€‚æµ‹è¯•å…¬éœ€è¯¾/ä¸“ä¸šè¯¾å­¦æ—¶ï¼Œè¯·ä½¿ç”¨å¹´ä»½2019/2020ã€‚æµ‹è¯•è¯¾ç¨‹è´­ä¹°ï¼Œé€€æ¬¾ç­‰ï¼Œè¯·ä½¿ç”¨å¹´ä»½2023ï¼Œè¯¾ç¨‹åç§°æ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­ã€‚æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®å¦‚ä¸‹ï¼š\n\n
        ä¸“æŠ€ä¸ªäººæ³¨å†ŒçŠ¶æ€ = {
        "372323199509260348": {
            "çŠ¶æ€": "å·²æ³¨å†Œ",
            "æ³¨å†Œæ—¶é—´": "2021-03-01",
            "æ³¨å†Œåœ°ç‚¹": "æµå—å¸‚",
            "ç®¡ç†å‘˜": "ç‹èŠ³èŠ³",
            "è§’è‰²": "ä¸“æŠ€ä¸ªäºº",
            "å•ä½": "å±±ä¸œçœæµå—å¸‚ä¸­å¿ƒåŒ»é™¢",
        },
    }

    ç”¨äººå•ä½æ³¨å†ŒçŠ¶æ€ = {
        "å±±ä¸œçœæµå—å¸‚ä¸­å¿ƒåŒ»é™¢": {
            "çŠ¶æ€": "å·²æ³¨å†Œ",
            "æ³¨å†Œæ—¶é—´": "2020-03-01",
            "æ³¨å†Œåœ°ç‚¹": "æµå—å¸‚",
            "ç®¡ç†å‘˜": "ç‹èŠ³èŠ³",
            "è§’è‰²": "ç”¨äººå•ä½",
            "ä¸Šçº§éƒ¨é—¨": "å±±ä¸œçœåŒ»ç–—åä¼š",
        }
    }

    å­¦æ—¶è®°å½• = {
        "372323199509260348": {
            "2019": {
                "å…¬éœ€è¯¾": [
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾1", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "åˆæ ¼"},
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾2", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "åˆæ ¼"},
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾3", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "æœªå®Œæˆ"},
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾4", "å­¦æ—¶": 10, "è¿›åº¦": 85, "è€ƒæ ¸": "æœªå®Œæˆ"},
                ],
                "ä¸“ä¸šè¯¾": [
                    {"è¯¾ç¨‹åç§°": "ä¸“ä¸šè¯¾1", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "åˆæ ¼"},
                    {"è¯¾ç¨‹åç§°": "ä¸“ä¸šè¯¾2", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "åˆæ ¼"},
                    {"è¯¾ç¨‹åç§°": "ä¸“ä¸šè¯¾3", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "æœªå®Œæˆ"},
                    {"è¯¾ç¨‹åç§°": "ä¸“ä¸šè¯¾4", "å­¦æ—¶": 10, "è¿›åº¦": 85, "è€ƒæ ¸": "æœªå®Œæˆ"},
                ],
            },
            "2020": {
                "å…¬éœ€è¯¾": [
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾5", "å­¦æ—¶": 10, "è¿›åº¦": 100, "è€ƒæ ¸": "æœªå®Œæˆ"},
                    {"è¯¾ç¨‹åç§°": "å…¬éœ€è¯¾6", "å­¦æ—¶": 10, "è¿›åº¦": 12, "è€ƒæ ¸": "æœªå®Œæˆ"},
                ],
                "ä¸“ä¸šè¯¾": [
                    {"è¯¾ç¨‹åç§°": "ä¸“ä¸šè¯¾5", "å­¦æ—¶": 10, "è¿›åº¦": 85, "è€ƒæ ¸": "æœªå®Œæˆ"},
                ],
            },
        }
    }

    è¯¾ç¨‹è´­ä¹°è®°å½• = {
        "372323199509260348": {
            "2023": {
                "æ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­": {
                    "è¯¾ç¨‹åç§°": "æ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­",
                    "è¯¾ç¨‹ç±»åˆ«": "ä¸“ä¸šè¯¾",
                    "å­¦æ—¶": 10,
                    "è¿›åº¦": 90,
                    "è€ƒæ ¸": "æœªå®Œæˆ",
                    "è´­ä¹°æ—¶é—´": "2023-01-01",
                    "è´­ä¹°åœ°ç‚¹": "å±±ä¸œçœæµå—å¸‚",
                    "åŸ¹è®­æœºæ„": "å±±ä¸œçœæ–°é—»å­¦é™¢",
                },
            },
            "2024": {
                "æ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­": {
                    "è¯¾ç¨‹åç§°": "æ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­",
                    "è¯¾ç¨‹ç±»åˆ«": "ä¸“ä¸šè¯¾",
                    "å­¦æ—¶": 10,
                    "è¿›åº¦": 0,
                    "è€ƒæ ¸": "æœªå®Œæˆ",
                    "è´­ä¹°æ—¶é—´": "2024-01-01",
                    "è´­ä¹°åœ°ç‚¹": "å±±ä¸œçœæµå—å¸‚",
                    "åŸ¹è®­æœºæ„": "å±±ä¸œçœæ–°é—»å­¦é™¢",
                },
            },
        }
    }
    """,
        }
    ]


class RegistrationStatusTool(BaseTool):
    """æŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€"""

    name: str = "æ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·"
    description: str = (
        "ç”¨äºæŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_number "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        # print(type(params))
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        if "user_id_number" not in params_dict:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        try:
            int(params_dict["user_id_number"])
        except ValueError:
            return "è¯·æŒ‡å®šæ‚¨æˆ–è€…ç®¡ç†å‘˜èº«ä»½è¯å·"
        input = params_dict["user_id_number"]
        if REGISTRATION_STATUS.get(input) is not None:
            status = REGISTRATION_STATUS.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str
        return "ç»æŸ¥è¯¢ï¼Œæ‚¨å°šæœªåœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šæ³¨å†Œ"


class RegistrationStatusToolIndividual(BaseTool):
    """æŸ¥è¯¢ä¸“æŠ€ä¸ªäººåœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€"""

    name: str = "ä¸“æŠ€ä¸ªäººæ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·"
    description: str = (
        "ç”¨äºæŸ¥è¯¢ä¸“æŠ€ä¸ªäººåœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€ï¼Œåªæœ‰å½“ç”¨æˆ·æ˜ç¡®æåŠéœ€è¦å¸®åŠ©æŸ¥è¯¢æ—¶è°ƒç”¨ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_number "
    )
    return_direct: bool = True

    def _run(self, params) -> Any:
        print(params)
        params_dict = params
        # try:
        #     params_dict = json.loads(params)
        # except json.JSONDecodeError:
        #     return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œè¯·æŒ‡å®š"
        if "user_id_number" not in params_dict:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œè¯·æŒ‡å®š"
        try:
            int(params_dict["user_id_number"])
        except Exception:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œè¯·æŒ‡å®š"
        input = str(params_dict["user_id_number"])
        if REGISTRATION_STATUS.get(input) is not None:
            status = REGISTRATION_STATUS.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str
        return f"å¾ˆæŠ±æ­‰ï¼Œæ ¹æ®æ‚¨æä¾›çš„èº«ä»½è¯å·ç {input}ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ³¨å†Œä¿¡æ¯ï¼Œè¯·ç¡®è®¤æ‚¨æä¾›äº†æ­£ç¡®çš„ä¿¡æ¯å¹¶é‡è¯•"

class RegistrationStatusToolUniversal(BaseTool):
    """æŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€"""

    name: str = "ç»Ÿä¸€æ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·"
    description: str = (
        "ç”¨äºæŸ¥è¯¢ç”¨æˆ·åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€ï¼Œåªæœ‰å½“ç”¨æˆ·æ˜ç¡®æåŠéœ€è¦å¸®åŠ©æŸ¥è¯¢æ—¶è°ƒç”¨ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šæŸ¥è¯¢å·ç  user_id_number "
    )
    return_direct: bool = True

    def _run(self, params) -> Any:
        print(params)
        params_dict = params
        # try:
        #     params_dict = json.loads(params)
        # except json.JSONDecodeError:
        #     return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œè¯·æŒ‡å®š"
        if "user_id_number" not in params_dict:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œå•ä½ä¿¡ç”¨ä»£ç ï¼Œæˆ–è€…å•ä½åç§°ï¼Œè¯·æŒ‡å®š"
        try:
            int(params_dict["user_id_number"])
        except Exception:
            try:
                str(params_dict["user_id_number"])
            except Exception:
                return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œå•ä½ä¿¡ç”¨ä»£ç ï¼Œæˆ–è€…å•ä½åç§°ï¼Œè¯·æŒ‡å®š"
        input = str(params_dict["user_id_number"])
        if input in ["unknown", "æœªçŸ¥"]:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„èº«ä»½è¯å·ç ï¼Œå•ä½ä¿¡ç”¨ä»£ç ï¼Œæˆ–è€…å•ä½åç§°ï¼Œè¯·æŒ‡å®š"
        if REGISTRATION_STATUS.get(input) is not None:
            status = REGISTRATION_STATUS.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str

        if REGISTRATION_STATUS_NON_IDV.get(input) is not None:
            status = REGISTRATION_STATUS_NON_IDV.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str
        return f"å¾ˆæŠ±æ­‰ï¼Œæ ¹æ®æ‚¨æä¾›çš„{input}ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ³¨å†Œä¿¡æ¯ï¼Œè¯·ç¡®è®¤æ‚¨æä¾›äº†æ­£ç¡®çš„ä¿¡æ¯å¹¶é‡è¯•"


class RegistrationStatusToolNonIndividual(BaseTool):
    """æŸ¥è¯¢ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨æˆ–ç»§ç»­æ•™è‚²æœºæ„åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€"""

    name: str = "éä¸ªäººæ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·"
    description: str = (
        "ç”¨äºæŸ¥è¯¢ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨æˆ–ç»§ç»­æ•™è‚²æœºæ„åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€ï¼Œåªæœ‰å½“ç”¨æˆ·æ˜ç¡®æåŠéœ€è¦å¸®åŠ©æŸ¥è¯¢æ—¶è°ƒç”¨ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_number "
    )
    return_direct: bool = True

    def _run(self, params) -> Any:
        print(params)
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„å•ä½ç®¡ç†å‘˜èº«ä»½è¯å·æˆ–è€…å•ä½åç§°æˆ–è€…ç»Ÿä¸€ä¿¡ç”¨ä»£ç ï¼Œè¯·æŒ‡å®š"
        if "user_id_number" not in params_dict:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„å•ä½ç®¡ç†å‘˜èº«ä»½è¯å·æˆ–è€…å•ä½åç§°æˆ–è€…ç»Ÿä¸€ä¿¡ç”¨ä»£ç ï¼Œè¯·æŒ‡å®š"
        try:
            str(params_dict["user_id_number"])
        except ValueError:
            return "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰æˆåŠŸè¯†åˆ«æ‚¨çš„å•ä½ç®¡ç†å‘˜èº«ä»½è¯å·æˆ–è€…å•ä½åç§°æˆ–è€…ç»Ÿä¸€ä¿¡ç”¨ä»£ç ï¼Œè¯·æŒ‡å®š"
        input = str(params_dict["user_id_number"])
        if REGISTRATION_STATUS_NON_IDV.get(input) is not None:
            status = REGISTRATION_STATUS_NON_IDV.get(input)
            ret_str = [f"{k}: {v}" for k, v in status.items()]
            ret_str = "  \n".join(ret_str)
            return "ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨å¤§ä¼—äº‘å­¦å¹³å°ä¸Šçš„æ³¨å†ŒçŠ¶æ€å¦‚ä¸‹ï¼š  \n" + ret_str
        return f"å¾ˆæŠ±æ­‰ï¼Œæ ¹æ®æ‚¨æä¾›çš„å·ç {input}ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ³¨å†Œä¿¡æ¯ï¼Œè¯·ç¡®è®¤æ‚¨æä¾›äº†æ­£ç¡®çš„ä¿¡æ¯å¹¶é‡è¯•"


class UpdateUserRoleTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ›´æ–°ç”¨æˆ·è§’è‰²"""

    name: str = "ç”¨æˆ·è§’è‰²æ›´æ–°å·¥å…·"
    description: str = (
        "ç”¨äºæ›´æ–°ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„è§’è‰²ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·è§’è‰² user_role "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        if "user_role" not in params_dict:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        user_role = params_dict["user_role"]
        if user_role not in ["ä¸“æŠ€ä¸ªäºº", "ç”¨äººå•ä½", "ä¸»ç®¡éƒ¨é—¨", "ç»§ç»­æ•™è‚²æœºæ„"]:
            return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        main_qa_agent_executor.agent.runnable.get_prompts()[0].template = (
            """Your ONLY job is to use a tool to answer the following question.

You MUST use a tool to answer the question. 
Simply Answer "æ‚¨èƒ½æä¾›æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„ç»†èŠ‚å—ï¼Ÿ" if you don't know the answer.
DO NOT answer the question without using a tool.

Current user role is """
            + user_role
            + """.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
        )
        # st.session_state.user_role = user_role
        return f"æ›´æ–°æ‚¨çš„ç”¨æˆ·è§’è‰²ä¸º{user_role}, è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨ï¼Ÿ"


class UpdateUserRoleTool2(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ›´æ–°ç”¨æˆ·è§’è‰²"""

    name: str = "ç”¨æˆ·è§’è‰²æ›´æ–°å·¥å…·"
    description: str = (
        "ç”¨äºæ›´æ–°ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„è§’è‰²ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·è§’è‰² user_role "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params, type(params))
        if isinstance(params, str):
            try:
                params_dict = json.loads(params)
            except json.JSONDecodeError:
                return 'æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        elif isinstance(params, dict):
            params_dict = params
        else:
            return 'æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        if params_dict is None:
            return 'æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        # try:
        #     params_dict = json.loads(params)
        # except json.JSONDecodeError:
        #     return "æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚"
        if "user_role" not in params_dict:
            return 'æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        if params_dict["user_role"] is None:
            return 'æ‚¨å¥½ï¼ŒæŠ±æ­‰æˆ‘æ²¡æœ‰æ£€æµ‹åˆ°æ‚¨æä¾›çš„ç”¨æˆ·ç±»å‹ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        # if not isinstance(params_dict["user_role"], dict):
        #     return 'æ‚¨å¥½ï¼ŒæŠ±æ­‰æˆ‘æ²¡æœ‰æ£€æµ‹åˆ°æ‚¨æä¾›çš„ç”¨æˆ·ç±»å‹ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·é—®æ‚¨æƒ³å’¨è¯¢é‚£ä¸ªç”¨æˆ·ç±»å‹ï¼Ÿï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'

        # user_role = list(params_dict["user_role"].values())[0]
        user_role = params_dict["user_role"]
        if user_role not in [
            "ä¸“æŠ€ä¸ªäºº",
            "ç”¨äººå•ä½",
            "ä¸»ç®¡éƒ¨é—¨",
            "ç»§ç»­æ•™è‚²æœºæ„",
            "è·³è¿‡",
        ]:
            return 'æ‚¨å¥½ï¼Œç›®å‰æˆ‘ä»¬æ”¯æŒçš„ç”¨æˆ·ç±»å‹ä¸ºä¸“æŠ€ä¸ªäººï¼Œç”¨äººå•ä½ï¼Œä¸»ç®¡éƒ¨é—¨å’Œç»§ç»­æ•™è‚²æœºæ„ï¼Œè¯·ç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ã€‚ï¼ˆå›å¤"è·³è¿‡"é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäººç”¨æˆ·ç±»å‹ï¼‰'
        if user_role == "è·³è¿‡":
            user_role = "ä¸“æŠ€ä¸ªäºº"
        main_qa_agent_executor.agent.runnable.get_prompts()[0].template = (
            """Your ONLY job is to use a tool to answer the following question.

You MUST use a tool to answer the question. 
Simply Answer "æ‚¨èƒ½æä¾›æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„ç»†èŠ‚å—ï¼Ÿ" if you don't know the answer.
DO NOT answer the question without using a tool.

Current user role is """
            + user_role
            + """.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
        )
        # st.session_state.user_role = user_role
        return f"æ›´æ–°æ‚¨çš„ç”¨æˆ·è§’è‰²ä¸º{user_role}, è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨ï¼Ÿ"


class CheckUserRoleTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·è§’è‰²"""

    name: str = "æ£€æŸ¥ç”¨æˆ·è§’è‰²å·¥å…·"
    description: str = "ç”¨äºæ£€æŸ¥ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„è§’è‰²ï¼Œæ— éœ€è¾“å…¥å‚æ•° "
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:
        print(params)
        template = main_qa_agent_executor.agent.runnable.get_prompts()[
            0
        ].template.lower()
        # print(template)
        start_index = template.find("current user role is") + len(
            "current user role is"
        )
        end_index = template.find("\n", start_index)
        result = template[start_index:end_index].strip()
        # result = st.session_state.get("user_role", "unknown")
        return result


class UpdateUserLocTool2(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ›´æ–°ç”¨æˆ·å­¦ä¹ åœ°å¸‚"""

    name: str = "ç”¨æˆ·å­¦ä¹ åœ°å¸‚æ›´æ–°å·¥å…·"
    description: str = (
        "ç”¨äºæ›´æ–°ç”¨æˆ·å­¦ä¹ åœ°å¸‚ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·å­¦ä¹ åœ°å¸‚ user_location "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    # def _run(self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None) -> Any:
    def _run(self, params) -> Any:
        print(params)
        # params_dict = params
        # try:
        #     params_dict = json.loads(params)
        # except json.JSONDecodeError:
        #     return (
        #         "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
        #         + LOC_STR
        #     )
        if isinstance(params, str):
            try:
                params_dict = json.loads(params)
            except json.JSONDecodeError:
                return (
                    "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                    + LOC_STR
                )
        elif isinstance(params, dict):
            params_dict = params
        else:
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        
        if params_dict is None:
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        if "user_location" not in params_dict:
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        user_location = params_dict["user_location"]
        if user_location is None:
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        if user_location == "unknown":
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        if user_location not in LOC_STR and user_location not in ["å¼€æ”¾å¤§å­¦", "èŸ¹å£³äº‘å­¦", "ä¸“æŠ€çŸ¥åˆ°", "æ–‡æ—…å…", "æ•™å¸ˆ"]:
            return (
                "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n"
                + LOC_STR
            )
        # if user_location not in LOC_STR:
        #     return "è¯·é—®æ‚¨æ˜¯åœ¨å“ªä¸ªåœ°å¸‚å¹³å°å­¦ä¹ çš„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„å­¦ä¹ åœ°å¸‚ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚æˆ‘æ–¹è´Ÿè´£çš„ä¸»è¦å¹³å°åœ°å¸‚æœ‰ï¼š\n\n" + LOC_STR
        credit_problem_chain_executor.agent.runnable.get_prompts()[0].template = (
            """Use a tool to answer the user's qustion.

You MUST use a tool and generate a response based on tool's output.
DO NOT hallucinate!!!!

Note that you may need to translate user inputs. Here are a few examples for translating user inputs:
- user: "å…¬éœ€", output: "å…¬éœ€è¯¾"
- user: "å…¬", output: "å…¬éœ€è¯¾"
- user: "ä¸“ä¸š", output: "ä¸“ä¸šè¯¾"
- user: "ä¸“", output: "ä¸“ä¸šè¯¾"
- user: "19å¹´", output: "2019"
- user: "19", output: "2019"
- user: "2019å¹´â€, output: "2019"

user location: """
            + user_location
            + """
You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
        )
        # st.session_state.user_role = user_role
        return f"è°¢è°¢ï¼Œå·²ä¸ºæ‚¨æ›´æ–°æ‚¨çš„å­¦ä¹ åœ°å¸‚ä¸º{user_location}, ç°åœ¨è¯·æ‚¨æä¾›èº«ä»½è¯å·ç ï¼Œä»¥ä¾¿æˆ‘æŸ¥è¯¢æ‚¨çš„å­¦æ—¶çŠ¶æ€ã€‚"


class CheckUserCreditTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€"""

    name: str = "æ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€å·¥å…·"
    description: str = (
        "ç”¨äºæ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_numberã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„å¹´ä»½ yearã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹ç±»å‹ course_type "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:

        params = params.replace("'", '"')
        print(params, type(params))
        CONTEXT_PROMPT = "You must ask the human about {context}. Reply with schema #2."
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError as e:
            print(e)
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"

        if "user_id_number" not in params_dict:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if isinstance(params_dict["user_id_number"], list):
            params_dict["user_id_number"] = params_dict["user_id_number"][0]
        if params_dict["user_id_number"] is None:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if len(params_dict["user_id_number"]) < 2:
            return "èº«ä»½è¯å·ä¼¼ä¹ä¸å¤ªå¯¹ï¼Œéº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨æ­£ç¡®çš„èº«ä»½è¯å·"

        if "year" not in params_dict:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if isinstance(params_dict["year"], list):
            params_dict["year"] = params_dict["year"][0]
        if params_dict["year"] is None:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if len(str(params_dict["year"])) < 2:
            return "å¹´åº¦ä¼¼ä¹ä¸å¤ªå¯¹ï¼Œéº»çƒ¦æ‚¨ç¡®è®¤ä½ çš„è¯¾ç¨‹å¹´åº¦ã€‚å¦‚ï¼š2019å¹´"

        if "course_type" not in params_dict:
            return "æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"
        if isinstance(params_dict["course_type"], list):
            params_dict["course_type"] = params_dict["course_type"][0]
        if params_dict["course_type"] is None:
            return "æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"
        if len(params_dict["course_type"]) < 2:
            return "è¯·ç¡®è®¤æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"

        user_id_number = str(params_dict["user_id_number"])
        year = re.search(r"\d+", str(params_dict["year"])).group()
        course_type = str(params_dict["course_type"])

        template = credit_problem_chain_executor.agent.runnable.get_prompts()[
            0
        ].template.lower()
        # print(template)
        start_index = template.find("user location: ") + len("user location: ")
        end_index = template.find("\n", start_index)
        user_provided_loc = template[start_index:end_index].strip()

        user_loc = REGISTRATION_STATUS[user_id_number]["æ³¨å†Œåœ°ç‚¹"]

        match_location = check_user_location(user_provided_loc, [user_loc])
        if match_location is not None:
            match_other_loc = check_user_location(user_provided_loc, [
                "å¼€æ”¾å¤§å­¦",
                "èŸ¹å£³äº‘å­¦",
                "ä¸“æŠ€çŸ¥åˆ°",
                "æ–‡æ—…å…",
                "æ•™å¸ˆ",
            ])
            if match_other_loc is not None:
                if match_other_loc == "æ–‡æ—…å…":
                    return "æœ¬å¹³å°åªæ˜¯æ¥æ”¶æ–¹ï¼Œå­¦æ—¶å¦‚æœå’Œæ‚¨å®é™…ä¸ç¬¦ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦æœ‰æ­£å¸¸æ¨é€è¿‡æ¥ï¼Œåªæœ‰æ¨é€äº†æˆ‘ä»¬æ‰èƒ½æ”¶åˆ°ï¼Œæ‰ä¼šæ˜¾ç¤ºå¯¹åº”å­¦æ—¶ã€‚"
                return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯çœç›´ï¼Œéçœç›´å•ä½å­¦æ—¶æ— æ³•å¯¹æ¥ã€‚"
            return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯{user_provided_loc}ï¼ŒåŒºåŸŸä¸ç¬¦å­¦æ—¶æ— æ³•å¯¹æ¥ï¼Œå»ºè®®æ‚¨å…ˆè¿›è¡Œâ€œå•ä½è°ƒè½¬â€,è°ƒè½¬åˆ°æ‚¨æ‰€åœ¨çš„åœ°å¸‚åï¼Œå†è”ç³»æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œæ¨é€å­¦æ—¶ã€‚"
        # if user_provided_loc not in user_loc and user_loc not in user_provided_loc:
        #     match_other_loc = check_user_location(user_provided_loc, [
        #         "å¼€æ”¾å¤§å­¦",
        #         "èŸ¹å£³äº‘å­¦",
        #         "ä¸“æŠ€çŸ¥åˆ°",
        #         "æ–‡æ—…å…",
        #         "æ•™å¸ˆ",
        #     ])
        #     if match_other_loc is not None:
        #         if user_provided_loc == "æ–‡æ—…å…":
        #             return "æœ¬å¹³å°åªæ˜¯æ¥æ”¶æ–¹ï¼Œå­¦æ—¶å¦‚æœå’Œæ‚¨å®é™…ä¸ç¬¦ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦æœ‰æ­£å¸¸æ¨é€è¿‡æ¥ï¼Œåªæœ‰æ¨é€äº†æˆ‘ä»¬æ‰èƒ½æ”¶åˆ°ï¼Œæ‰ä¼šæ˜¾ç¤ºå¯¹åº”å­¦æ—¶ã€‚"
        #         return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯çœç›´ï¼Œéçœç›´å•ä½å­¦æ—¶æ— æ³•å¯¹æ¥ã€‚"
        #     return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯{user_provided_loc}ï¼ŒåŒºåŸŸä¸ç¬¦å­¦æ—¶æ— æ³•å¯¹æ¥ï¼Œå»ºè®®æ‚¨å…ˆè¿›è¡Œâ€œå•ä½è°ƒè½¬â€,è°ƒè½¬åˆ°æ‚¨æ‰€åœ¨çš„åœ°å¸‚åï¼Œå†è”ç³»æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œæ¨é€å­¦æ—¶ã€‚"
        else:
            # if user_provided_loc in [
            #     "å¼€æ”¾å¤§å­¦",
            #     "èŸ¹å£³äº‘å­¦",
            #     "ä¸“æŠ€çŸ¥åˆ°",
            #     "æ–‡æ—…å…",
            #     "æ•™å¸ˆ",
            # ]:
            match_other_loc = check_user_location(user_provided_loc, [
                "å¼€æ”¾å¤§å­¦",
                "èŸ¹å£³äº‘å­¦",
                "ä¸“æŠ€çŸ¥åˆ°",
                "æ–‡æ—…å…",
                "æ•™å¸ˆ",
            ])
            if match_other_loc is not None:
                return "è¯·å…ˆå’¨è¯¢æ‚¨å…·ä½“çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦æœ‰æ­£å¸¸æ¨é€è¿‡æ¥ï¼Œåªæœ‰æ¨é€äº†æˆ‘ä»¬æ‰èƒ½æ”¶åˆ°ï¼Œæ‰ä¼šæ˜¾ç¤ºå¯¹åº”å­¦æ—¶ã€‚"
            hours = CREDIT_HOURS.get(user_id_number)
            if hours is None:
                return "ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨çš„ä»»ä½•å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            year_hours = hours.get(year)
            if year_hours is None:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦çš„ä»»ä½•å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            course_year_hours = year_hours.get(course_type)
            if course_year_hours is None:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            if len(course_year_hours) == 0:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            total_hours = sum([x["å­¦æ—¶"] for x in course_year_hours])
            finished_hours = sum(
                [
                    x["å­¦æ—¶"]
                    for x in course_year_hours
                    if x["è¿›åº¦"] == 100 and x["è€ƒæ ¸"] == "åˆæ ¼"
                ]
            )
            unfinished_courses = [
                f"{x['è¯¾ç¨‹åç§°']}å®Œæˆäº†{x['è¿›åº¦']}%"
                for x in course_year_hours
                if x["è¿›åº¦"] < 100
            ]
            untested_courses = [
                x["è¯¾ç¨‹åç§°"] for x in course_year_hours if x["è€ƒæ ¸"] == "æœªå®Œæˆ"
            ]
            unfinished_str = "  \n\n".join(unfinished_courses)
            untested_str = "  \n\n".join(untested_courses)

            res_str = f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶æƒ…å†µå¦‚ä¸‹ï¼š  \n\n"
            res_str += f"æ‚¨æŠ¥åçš„æ€»å­¦æ—¶ï¼š{total_hours}  \n\n"
            res_str += f"å·²å®Œæˆå­¦æ—¶ï¼š{finished_hours}  \n\n"
            res_str += f"å…¶ä¸­ï¼Œä»¥ä¸‹å‡ èŠ‚è¯¾è¿›åº¦è¿˜æ²¡æœ‰è¾¾åˆ°100%ï¼Œæ¯èŠ‚è¯¾è¿›åº¦çœ‹åˆ°100%åæ‰èƒ½è®¡å…¥å­¦æ—¶  \n\n"
            res_str += unfinished_str + "  \n\n"
            res_str += f"ä»¥ä¸‹å‡ èŠ‚è¯¾è¿˜æ²¡æœ‰å®Œæˆè€ƒè¯•ï¼Œè€ƒè¯•é€šè¿‡åæ‰èƒ½è®¡å…¥å­¦æ—¶  \n\n"
            res_str += untested_str + "  \n\n"
            return res_str


class CheckUserCreditTool2(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€"""

    name: str = "æ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€å·¥å…·"
    description: str = (
        "ç”¨äºæ£€æŸ¥ç”¨æˆ·å­¦æ—¶çŠ¶æ€ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_numberã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„å¹´ä»½ yearã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹ç±»å‹ course_type "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:

        # params = params.replace("'", '"')
        print(params, type(params))
        # params_dict = params
        if isinstance(params, str):
            try:
                params_dict = json.loads(params)
            except json.JSONDecodeError as e:
                print(e)
                return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"
        elif isinstance(params, dict):
            params_dict = params
        else:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"
        # try:
        #     params_dict = json.loads(params)
        # except json.JSONDecodeError as e:
        #     print(e)
        #     return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"

        if "user_id_number" not in params_dict:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if isinstance(params_dict["user_id_number"], list):
            params_dict["user_id_number"] = params_dict["user_id_number"][0]
        if params_dict["user_id_number"] is None:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if len(params_dict["user_id_number"]) < 2:
            return "èº«ä»½è¯å·ä¼¼ä¹ä¸å¤ªå¯¹ï¼Œéº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨æ­£ç¡®çš„èº«ä»½è¯å·"

        if "year" not in params_dict:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if isinstance(params_dict["year"], list):
            params_dict["year"] = params_dict["year"][0]
        if params_dict["year"] is None:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if len(str(params_dict["year"])) < 2:
            return "å¹´åº¦ä¼¼ä¹ä¸å¤ªå¯¹ï¼Œéº»çƒ¦æ‚¨ç¡®è®¤ä½ çš„è¯¾ç¨‹å¹´åº¦ã€‚å¦‚ï¼š2019å¹´"

        if "course_type" not in params_dict:
            return "æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"
        if isinstance(params_dict["course_type"], list):
            params_dict["course_type"] = params_dict["course_type"][0]
        if params_dict["course_type"] is None:
            return "æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"
        if len(params_dict["course_type"]) < 2:
            return "è¯·ç¡®è®¤æ‚¨è¦æŸ¥è¯¢çš„æ˜¯å…¬éœ€è¯¾è¿˜æ˜¯ä¸“ä¸šè¯¾"

        user_id_number = str(params_dict["user_id_number"])
        year = re.search(r"\d+", str(params_dict["year"])).group()
        course_type = str(params_dict["course_type"])

        template = credit_problem_chain_executor.agent.runnable.get_prompts()[
            0
        ].template.lower()
        # print(template)
        start_index = template.find("user location: ") + len("user location: ")
        end_index = template.find("\n", start_index)
        user_provided_loc = template[start_index:end_index].strip()

        user_loc = REGISTRATION_STATUS[user_id_number]["æ³¨å†Œåœ°ç‚¹"]

        if user_provided_loc not in user_loc and user_loc not in user_provided_loc:
            if user_provided_loc in [
                "å¼€æ”¾å¤§å­¦",
                "èŸ¹å£³äº‘å­¦",
                "ä¸“æŠ€çŸ¥åˆ°",
                "æ–‡æ—…å…",
                "æ•™å¸ˆ",
            ]:
                return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯çœç›´ï¼Œéçœç›´å•ä½å­¦æ—¶æ— æ³•å¯¹æ¥ã€‚"
            return f"ç»æŸ¥è¯¢æ‚¨æœ¬å¹³å°çš„å•ä½æ‰€åœ¨åŒºåŸŸæ˜¯{user_loc}ï¼Œä¸æ˜¯{user_provided_loc}ï¼ŒåŒºåŸŸä¸ç¬¦å­¦æ—¶æ— æ³•å¯¹æ¥ï¼Œå»ºè®®æ‚¨å…ˆè¿›è¡Œâ€œå•ä½è°ƒè½¬â€,è°ƒè½¬åˆ°æ‚¨æ‰€åœ¨çš„åœ°å¸‚åï¼Œå†è”ç³»æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œæ¨é€å­¦æ—¶ã€‚"
        else:
            if user_provided_loc in [
                "å¼€æ”¾å¤§å­¦",
                "èŸ¹å£³äº‘å­¦",
                "ä¸“æŠ€çŸ¥åˆ°",
                "æ–‡æ—…å…",
                "æ•™å¸ˆ",
            ]:
                return "è¯·å…ˆå’¨è¯¢æ‚¨å…·ä½“çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦æœ‰æ­£å¸¸æ¨é€è¿‡æ¥ï¼Œåªæœ‰æ¨é€äº†æˆ‘ä»¬æ‰èƒ½æ”¶åˆ°ï¼Œæ‰ä¼šæ˜¾ç¤ºå¯¹åº”å­¦æ—¶ã€‚"
            hours = CREDIT_HOURS.get(user_id_number)
            if hours is None:
                return "ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨çš„ä»»ä½•å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            year_hours = hours.get(year)
            if year_hours is None:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦çš„ä»»ä½•å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            course_year_hours = year_hours.get(course_type)
            if course_year_hours is None:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            if len(course_year_hours) == 0:
                return f"ç»æŸ¥è¯¢ï¼Œå¹³å°è¿˜æœªæ¥æ”¶åˆ°æ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶ä¿¡æ¯ï¼Œå»ºè®®æ‚¨å…ˆå’¨è¯¢æ‚¨çš„å­¦ä¹ åŸ¹è®­å¹³å°ï¼Œå­¦æ—¶æ˜¯å¦å…¨éƒ¨æ¨é€ï¼Œå¦‚æœå·²ç¡®å®šæœ‰æ¨é€ï¼Œè¯·æ‚¨24å°æ—¶åŠæ—¶æŸ¥çœ‹å¯¹æ¥æƒ…å†µï¼›æ¯å¹´7æœˆè‡³9æœˆï¼Œå› å­¦æ—¶å¯¹æ¥æ•°æ®è¾ƒå¤§ï¼Œæ­¤é˜¶æ®µå»ºè®®1-3å¤©åŠæ—¶å…³æ³¨ã€‚"
            total_hours = sum([x["å­¦æ—¶"] for x in course_year_hours])
            finished_hours = sum(
                [
                    x["å­¦æ—¶"]
                    for x in course_year_hours
                    if x["è¿›åº¦"] == 100 and x["è€ƒæ ¸"] == "åˆæ ¼"
                ]
            )
            unfinished_courses = [
                f"{x['è¯¾ç¨‹åç§°']}å®Œæˆäº†{x['è¿›åº¦']}%"
                for x in course_year_hours
                if x["è¿›åº¦"] < 100
            ]
            untested_courses = [
                x["è¯¾ç¨‹åç§°"] for x in course_year_hours if x["è€ƒæ ¸"] == "æœªå®Œæˆ"
            ]
            unfinished_str = "  \n\n".join(unfinished_courses)
            untested_str = "  \n\n".join(untested_courses)

            res_str = f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦{course_type}çš„å­¦æ—¶æƒ…å†µå¦‚ä¸‹ï¼š  \n\n"
            res_str += f"æ‚¨æŠ¥åçš„æ€»å­¦æ—¶ï¼š{total_hours}  \n\n"
            res_str += f"å·²å®Œæˆå­¦æ—¶ï¼š{finished_hours}  \n\n"
            res_str += f"å…¶ä¸­ï¼Œä»¥ä¸‹å‡ èŠ‚è¯¾è¿›åº¦è¿˜æ²¡æœ‰è¾¾åˆ°100%ï¼Œæ¯èŠ‚è¯¾è¿›åº¦çœ‹åˆ°100%åæ‰èƒ½è®¡å…¥å­¦æ—¶  \n\n"
            res_str += unfinished_str + "  \n\n"
            res_str += f"ä»¥ä¸‹å‡ èŠ‚è¯¾è¿˜æ²¡æœ‰å®Œæˆè€ƒè¯•ï¼Œè€ƒè¯•é€šè¿‡åæ‰èƒ½è®¡å…¥å­¦æ—¶  \n\n"
            res_str += untested_str + "  \n\n"
            return res_str


class RefundTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•"""

    name: str = "æ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•å·¥å…·"
    description: str = (
        "ç”¨äºæ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_numberã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹å¹´ä»½ yearã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹åç§° course_name "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:

        params = params.replace("'", '"')
        print(params, type(params))
        try:
            params_dict = json.loads(params)
        except json.JSONDecodeError as e:
            print(e)
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"

        if "user_id_number" not in params_dict:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if params_dict["user_id_number"] is None:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if len(params_dict["user_id_number"]) < 2:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨æ­£ç¡®çš„èº«ä»½è¯å·"
        
        if "year" not in params_dict:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if params_dict["year"] is None:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if len(params_dict["year"]) < 4:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        
        if "course_name" not in params_dict:
            return "æ‚¨é—®çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"
        if params_dict["course_name"] is None:
            return "æ‚¨é—®çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"
        if len(params_dict["course_name"]) < 2:
            return "æ‚¨é—®çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"

        user_id_number = params_dict["user_id_number"]

        year = params_dict["year"]
        year = re.search(r"\d+", year).group()

        course_name = params_dict["course_name"]
        if COURSE_PURCHASES.get(user_id_number) is not None:
            purchases = COURSE_PURCHASES.get(user_id_number)
            if year in purchases:
                if course_name in purchases[year]:
                    progress = purchases[year][course_name]["è¿›åº¦"]
                    if progress == 0:
                        return "ç»æŸ¥è¯¢æ‚¨çš„è¿™ä¸ªè¯¾ç¨‹æ²¡æœ‰å­¦ä¹ ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»å³ä¸Šæ–¹ã€æˆ‘çš„å­¦ä¹ ã€‘ï¼Œé€‰æ‹©ã€æˆ‘çš„è®¢å•ã€‘ï¼Œæ‰¾åˆ°å¯¹åº”è¯¾ç¨‹ç‚¹å‡»ã€ç”³è¯·å”®åã€‘ï¼Œè´¹ç”¨åœ¨1ä¸ªå·¥ä½œæ—¥ä¼šåŸè·¯é€€å›ã€‚"
                    return f"ç»æŸ¥è¯¢ï¼Œæ‚¨çš„è¯¾ç¨‹{course_name}å­¦ä¹ è¿›åº¦ä¸º{progress}%ï¼Œå¯ä»¥æŒ‰ç…§æœªå­¦çš„æ¯”ä¾‹é€€è´¹ï¼Œå¦‚éœ€é€€è´¹è¯·è”ç³»å¹³å°çš„äººå·¥çƒ­çº¿å®¢æœæˆ–è€…åœ¨çº¿å®¢æœè¿›è¡Œåé¦ˆã€‚"
                return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"
            return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"
        return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"


class CheckPurchaseTool(BaseTool):
    """æ ¹æ®ç”¨æˆ·å›ç­”ï¼Œæ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•"""

    name: str = "æ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•å·¥å…·"
    description: str = (
        "ç”¨äºæ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•ï¼Œéœ€è¦æŒ‡é€šè¿‡ json æŒ‡å®šç”¨æˆ·èº«ä»½è¯å· user_id_numberã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹å¹´ä»½ yearã€ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹åç§° course_name "
    )
    # args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(self, params) -> Any:

        params = params.replace("'", '"')
        print(params, type(params))
        try:
            params_dict = json.loads(params)
            params_dict = {k: str(v) for k, v in params_dict.items()}
        except json.JSONDecodeError as e:
            print(e)
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·ï¼Œæˆ‘è¿™è¾¹å¸®æ‚¨æŸ¥ä¸€ä¸‹"

        if "user_id_number" not in params_dict:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if params_dict["user_id_number"] is None:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨çš„èº«ä»½è¯å·"
        if len(str(params_dict["user_id_number"])) < 2:
            return "éº»çƒ¦æ‚¨æä¾›ä¸€ä¸‹æ‚¨æ­£ç¡®çš„èº«ä»½è¯å·"
        
        if "year" not in params_dict:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if params_dict["year"] is None:
            return "æ‚¨é—®çš„æ˜¯å“ªä¸ªå¹´åº¦çš„è¯¾ç¨‹ï¼Ÿå¦‚ï¼š2019å¹´"
        if len(str(params_dict["year"])) < 4:
            return "éº»çƒ¦æ‚¨ç¡®è®¤ä½ çš„è¯¾ç¨‹å¹´åº¦ã€‚å¦‚ï¼š2019å¹´"
        
        if "course_name" not in params_dict:
            return "æ‚¨é—®çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"
        if params_dict["course_name"] is None:
            return "æ‚¨é—®çš„è¯¾ç¨‹åç§°æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"
        if len(params_dict["course_name"]) < 2:
            return "è¯·æ‚¨æä¾›æ‚¨æƒ³è¦æŸ¥è¯¢çš„è¯¾ç¨‹çš„æ­£ç¡®åç§°ã€‚å¦‚ï¼šæ–°é—»ä¸“ä¸šè¯¾åŸ¹è®­ç­"
            

        user_id_number = params_dict["user_id_number"]

        year = params_dict["year"]
        year = re.search(r"\d+", year).group()

        course_name = params_dict["course_name"]
        if COURSE_PURCHASES.get(user_id_number) is not None:
            purchases = COURSE_PURCHASES.get(user_id_number)
            if year in purchases:
                if course_name in purchases[year]:
                    progress = purchases[year][course_name]["è¿›åº¦"]
                    if progress == 0:
                        return f"ç»æŸ¥è¯¢ï¼Œæ‚¨å·²ç»è´­ä¹°{year}å¹´åº¦çš„{course_name}ï¼Œè¯·å‰å¾€ä¸“ä¸šè¯¾å¹³å°ï¼Œç‚¹å‡»å³ä¸Šæ–¹ã€æˆ‘çš„å­¦ä¹ ã€‘æ‰¾åˆ°å¯¹åº”è¯¾ç¨‹ç›´æ¥å­¦ä¹ ã€‚"
                    return f"ç»æŸ¥è¯¢ï¼Œæ‚¨å·²ç»è´­ä¹°{year}å¹´åº¦çš„{course_name}ï¼Œæ‚¨çš„å­¦ä¹ è¿›åº¦ä¸º{progress}%ã€‚è¯·å‰å¾€ä¸“ä¸šè¯¾å¹³å°ï¼Œç‚¹å‡»å³ä¸Šæ–¹ã€æˆ‘çš„å­¦ä¹ ã€‘æ‰¾åˆ°å¯¹åº”è¯¾ç¨‹ç»§ç»­å­¦ä¹ ã€‚"
                return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"
            return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"
        return f"ç»æŸ¥è¯¢ï¼Œæ‚¨åœ¨{year}å¹´åº¦ï¼Œæ²¡æœ‰è´­ä¹°{course_name}ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„è¯¾ç¨‹åç§°ã€å¹´åº¦ã€èº«ä»½è¯å·æ˜¯å¦æ­£ç¡®ã€‚"


@st.cache_resource
def create_retrieval_tool(
    markdown_path,
    tool_name,
    tool_description,
    chunk_size: int = 100,
    chunk_overlap: int = 30,
    separators: List[str] = None,
    search_kwargs: dict = None,
    return_retriever: bool = False,
    rerank: bool = False,
    use_cached_faiss: bool = True,
):
    # Load files
    loader = UnstructuredMarkdownLoader(markdown_path)
    docs = loader.load()

    # Declare the embedding model
    embeddings = DashScopeEmbeddings(
        model="text-embedding-v2",
    )
    # embeddings = OpenAIEmbeddings()

    if os.path.exists(f"./vector_store/{tool_name}.faiss") and use_cached_faiss:
        vector = FAISS.load_local(
            f"./vector_store/{tool_name}.faiss",
            embeddings,
            allow_dangerous_deserialization=True,
        )
    else:
        #=============only split by separaters============
        documents = []
        all_content = docs[0].page_content
        texts = [sentence for sentence in all_content.split("\n\n")]
        meta_data = [docs[0].metadata] * len(texts)
        for content, meta in zip(texts, meta_data):
            new_doc = Document(page_content=content, metadata=meta)
            documents.append(new_doc)

        print(documents)
        vector = FAISS.from_documents(documents, embeddings)

        vector.save_local(f"./vector_store/{tool_name}.faiss")
    # Create a retriever tool
    if search_kwargs is None:
        retriever = vector.as_retriever()
    else:
        retriever = vector.as_retriever(search_kwargs=search_kwargs)

    # if rerank:
    #     # compressor = CohereRerank()
    #     compressor = FlashrankRerank()
    #     retriever = ContextualCompressionRetriever(
    #         base_compressor=compressor, base_retriever=retriever
    #     )

    registration_tool = create_retriever_tool(
        retriever,
        name=tool_name,
        description=tool_description,
    )
    
    registration_tool.return_direct=True
    if return_retriever:
        return registration_tool, retriever
    return registration_tool


# CREATE RETRIEVERS
individual_qa_tool = create_retrieval_tool(
    "./policies_v2/individual_q.md",
    "individual_qa_engine",
    "å›ç­”ä¸ªäººç”¨æˆ·çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
    use_cached_faiss=True,
)

employing_unit_qa_tool = create_retrieval_tool(
    "./policies_v2/employing_unit_q.md",
    "employing_unit_qa_engine",
    "å›ç­”ç”¨äººå•ä½ç”¨æˆ·çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
    use_cached_faiss=True,
)

supervisory_department_qa_tool = create_retrieval_tool(
    "./policies_v2/supervisory_dept_q.md",
    "supervisory_department_qa_engine",
    "å›ç­”ä¸»ç®¡éƒ¨é—¨ç”¨æˆ·çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
    use_cached_faiss=True,
)

cont_edu_qa_tool = create_retrieval_tool(
    "./policies_v2/cont_edu_q.md",
    "cont_edu_qa_engine",
    "å›ç­”ç»§ç»­æ•™è‚²æœºæ„ç”¨æˆ·çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼š",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
    use_cached_faiss=True,
)


login_problems_detail_tool = create_retrieval_tool(
    "./policies_v2/login_problems_details_q.md",
    "login_problems_detail_engine",
    "å›ç­”ç”¨æˆ·ç™»å½•é—®é¢˜çš„ç»†èŠ‚ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šæ²¡æœ‰æ»‘å—ï¼Œæ‰¾ä¸åˆ°æ»‘å—ï¼Œç™»å½•ä¸ºä»€ä¹ˆæç¤ºéªŒè¯å¤±è´¥ï¼Œå“ªé‡Œæœ‰æ»‘å—ï¼Œå¯†ç é”™è¯¯ï¼Œå¿˜è®°å¯†ç ï¼Œè´¦å·ä¸å­˜åœ¨ï¼Œç™»å½•æ˜¾ç¤ºå®¡æ ¸ä¸­",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
)

forgot_password_tool = create_retrieval_tool(
    "./policies_v2/forgot_password_q.md",
    "forgot_password_engine",
    "å›ç­”ç”¨æˆ·å¿˜è®°å¯†ç çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œå¦‚ï¼šå¿˜è®°å¯†ç æ€ä¹ˆåŠï¼Œå¯†ç å¿˜è®°äº†ï¼Œæ‰¾å›å¯†ç ï¼Œå¿˜è®°å¯†ç æ‰‹æœºå·é‚£é‡Œæ€ä¹ˆæ˜¯ç©ºçš„ã€æ‰‹æœºå·ä¸æ˜¾ç¤ºã€æ‰‹æœºå·æ€ä¹ˆä¿®æ”¹ã€æ‰‹æœºå·ä¸ç”¨äº†ï¼Œæ€ä¹ˆæ‰¾å›ã€å§“åæˆ–èº«ä»½è¯å·æˆ–æ‰€åœ¨å•ä½æœ‰è¯¯ã€æç¤ºä»€ä¹ˆå§“åé”™è¯¯ã€èº«ä»½è¯å·é”™è¯¯ã€æ‰€åœ¨å•ä½æœ‰è¯¯ã€å¯†ç æ€ä¹ˆä¿å­˜ä¸äº†ã€æ”¹å¯†ç æ€ä¹ˆä¸è¡Œã€æ”¹å¯†ç æ€ä¹ˆä¿å­˜ä¸äº†ã€å¯†ç ä¿å­˜ä¸äº†",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
)

# æµå®å¸‚
jn_city_tool = create_retrieval_tool(
    "./policies_v2/jining_q.md",
    "jn_city_engine",
    "å›ç­”æœ‰å…³æµå®å¸‚æŠ¥ç­ç¼´è´¹ï¼Œåœ¨çº¿å­¦ä¹ å’Œç¼´è´¹çš„ç›¸å…³é—®é¢˜ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£",
    search_kwargs={"k": 3},
    chunk_size=100,
    separators=["\n\n"],
)


tools = [
    # multiply,
    RegistrationStatusTool(),
    # AskForUserRoleTool(),
    UpdateUserRoleTool(),
    # registration_tool,
    # auditing_tool,
    # withdrawal_tool,
    # faq_personal_tool,
    # faq_employing_unit_tool,
    # faq_cont_edu_tool,
    # cannot_register_tool,
    # login_problems_tool,
    # login_problems_detail_tool,
    # forgot_password_tool,
    # individual_operation_tool,
    # employing_unit_operation_tool,
    # supervisory_department_operation_tool,
    # personal_modify_info_tool,
    # employ_supervise_modify_info_tool,
    # cont_edu_modify_info_tool,
    # complaints_tool,
    # policy_inquiry_tool,
    # other_questions_tool,
    # online_learning_and_tests_tool,
    # payments_tool,
    # certificate_and_hours_tool
]

# DO NOT hallucinate!!! You MUST use a tool to collect information to answer the questions!!! ALWAYS use a tool to answer a question if possible. Otherwise, you MUST ask the user for more information.
# prompt = hub.pull("hwchase17/react")
prompt = PromptTemplate.from_template(
    """Your ONLY job is to use a tool to answer the following question.

You MUST use a tool to answer the question. 
Simply Answer "æ‚¨èƒ½æä¾›æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„ç»†èŠ‚å—ï¼Ÿ" if you don't know the answer.
DO NOT answer the question without using a tool.

Current user role is unknown.

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
)
prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
    "chat_history",
]

memory = ConversationBufferMemory(memory_key="chat_history", input_key="input")
agent = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}), tools, prompt
)
main_qa_agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent, tools=tools, memory=memory, verbose=True, handle_parsing_errors=True
)

# check user role agent
check_user_role_router_prompt = PromptTemplate.from_template(
    """Your ONLY job is to determine the user role. DO NOT Answer the question.

You MUST use a tool to find out the user role.
DO NOT hallucinate!!!!

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you will not answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!


Question: {input}
Thought:{agent_scratchpad}
user role:
"""
)
check_user_role_router_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
]

check_user_role_router_tools = [CheckUserRoleTool()]

check_user_role_router_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    # ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3),
    check_user_role_router_tools,
    check_user_role_router_prompt,
)
check_user_role_router_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=check_user_role_router_chain,
    tools=check_user_role_router_tools,
    verbose=True,
    handle_parsing_errors=True,
)

# Update user role agent
update_user_role_prompt = PromptTemplate.from_template(
    """Your ONLY job is to ask the user to provide their role information regardless of the input.

You MUST ALWAYS say: è¯·é—®æ‚¨æ˜¯ä¸“æŠ€ä¸ªäººã€ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨ï¼Œè¿˜æ˜¯ç»§ç»­æ•™è‚²æœºæ„ï¼Ÿè¯·å…ˆç¡®è®¤æ‚¨çš„ç”¨æˆ·ç±»å‹ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æä¾›ç›¸åº”çš„ä¿¡æ¯ã€‚
You MUST use a tool to update user role.
DO NOT hallucinate!!!!

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!


Question: {input}
Thought:{agent_scratchpad}
"""
)
update_user_role_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
]

update_user_role_tools = [UpdateUserRoleTool()]

update_user_role_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    # ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3),
    update_user_role_tools,
    update_user_role_prompt,
)
update_user_role_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=update_user_role_chain,
    tools=update_user_role_tools,
    verbose=True,
    handle_parsing_errors=True,
)


# å¸¸è§„é—®é¢˜å’¨è¯¢
# summarization_llm_prompt = PromptTemplate.from_template(
#     """ ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœç”¨æˆ·æä¾›äº†åé¦ˆæˆ–å»ºè®®ï¼Œè¯·ä» context ä¸­æå–æœ€ç›¸å…³çš„å›å¤è¯æœ¯ï¼Œæ€»ç»“å¹¶å›å¤ã€‚
#     {context}
    
#     ä¸è¦æ·»åŠ ä»»ä½•æ–°çš„ä¿¡æ¯ï¼Œåªéœ€è¦æ€»ç»“åŸæ–‡çš„å†…å®¹å¹¶å›ç­”é—®é¢˜ã€‚
#     ä¸è¦æä¾›ä»»ä½•ä¸ªäººè§‚ç‚¹æˆ–è€…è¯„è®ºã€‚
#     ä¸è¦äº§ç”Ÿå¹»è§‰ã€‚

#     è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
#     {input}
#     """
# )
# summarization_llm_prompt.input_variables = ["input"]
# summarization_llm = Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3})

individual_qa_agent_executor_v2 = create_atomic_retriever_agent(
    tools=[individual_qa_tool, RegistrationStatusToolIndividual()],
    qa_map_path = "./policies_v2/individual_qa_map.json"
    # summarization_llm=summarization_llm,
    # summarization_llm_prompt=summarization_llm_prompt,
)
employing_unit_qa_agent_executor_v2 = create_atomic_retriever_agent(
    tools=[employing_unit_qa_tool, RegistrationStatusToolNonIndividual()],
    qa_map_path = "./policies_v2/employing_unit_qa_map.json"
    # summarization_llm=summarization_llm,
    # summarization_llm_prompt=summarization_llm_prompt,
)
supervisory_department_qa_agent_executor_v2 = create_atomic_retriever_agent(
    tools=[supervisory_department_qa_tool, RegistrationStatusToolNonIndividual()],
    qa_map_path = "./policies_v2/supervisory_dept_qa_map.json"
    # summarization_llm=summarization_llm,
    # summarization_llm_prompt=summarization_llm_prompt,
)
cont_edu_qa_agent_executor_v2 = create_atomic_retriever_agent(
    tools=[cont_edu_qa_tool, RegistrationStatusToolNonIndividual()],
    qa_map_path = "./policies_v2/cont_edu_qa_map.json"
    # summarization_llm=summarization_llm,
    # summarization_llm_prompt=summarization_llm_prompt,
)

# individual_qa_agent_executor_v2 = create_react_agent_with_memory(
#     tools=[individual_qa_tool, RegistrationStatusToolIndividual()],
#     prompt_str="""Your ONLY job is to use a tool to answer the following question.

#         You MUST use a tool to answer the question. DO NOT answer the question directly.
#         Simply Answer "æ‚¨èƒ½æä¾›æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„ç»†èŠ‚å—ï¼Ÿ" if you don't know the answer.
#         DO NOT answer the question without using a tool.
#         IF AND ONLY IF the user explicitly mentions they need help looking up registration status should you use the ä¸“æŠ€ä¸ªäººæ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…· tool.
#         If you think none of the tools are relevant, default to using individual_qa_engine.

#         A few examples:
#         - user: "æˆ‘æƒ³çŸ¥é“æˆ‘çš„æ³¨å†ŒçŠ¶æ€", è°ƒç”¨ ä¸“æŠ€ä¸ªäººæ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·
#         - user: "æˆ‘ä¸çŸ¥é“æˆ‘æ³¨å†Œäº†æ²¡æœ‰", è°ƒç”¨ ä¸“æŠ€ä¸ªäººæ³¨å†ŒçŠ¶æ€æŸ¥è¯¢å·¥å…·
#         - user: "æ€ä¹ˆæŸ¥çœ‹æ³¨å†Œå¾…å®¡æ ¸ä¿¡æ¯", è°ƒç”¨ individual_qa_engine
#         - user: "æ€ä¹ˆå®¡æ ¸ï¼Ÿ", è°ƒç”¨ individual_qa_engine
#         - user: "æœ‰äººç¤¾ç”µè¯å—", è°ƒç”¨ individual_qa_engine


#         Please keep your answers short and to the point.

#         You have access to the following tools:

#         {tools}

#         Use the following format:

#         Question: the input question you must answer
#         Thought: you should always think about what to do.
#         Action: the action to take, should be one of [{tool_names}]
#         Action Input: the input to the action
#         Observation: the result of the action
#         ... (this Thought/Action/Action Input/Observation can repeat N times)
#         Thought: I now know the final answer
#         Final Answer: the final answer to the original input question

#         Begin!

#         {chat_history}
#         Question: {input}
#         Thought:{agent_scratchpad}
#         """
# )

# employing_unit_qa_agent_executor_v2 = create_react_agent_with_memory(
#     tools=[employing_unit_qa_tool, RegistrationStatusToolNonIndividual()],
# )

# supervisory_department_qa_agent_executor_v2 = create_react_agent_with_memory(
#     tools=[supervisory_department_qa_tool, RegistrationStatusToolNonIndividual()],
# )

# cont_edu_qa_agent_executor_v2 = create_react_agent_with_memory(
#     tools=[cont_edu_qa_tool, RegistrationStatusToolNonIndividual()],
# )

# update_user_role_agent = create_single_function_call_agent(UpdateUserRoleTool2())
update_user_role_tools = [UpdateUserRoleTool2(), RegistrationStatusToolUniversal()]
update_user_role_agent = create_atomic_retriever_agent(
    tools=update_user_role_tools,
    system_prompt=f"""ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ã€‚ä»¥ä¸‹æ˜¯æ¯ä¸ªå·¥å…·çš„åç§°å’Œæè¿°ï¼š

        {render_text_description(update_user_role_tools)}
        
        ### ä»»åŠ¡
        æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ input, ä½ éœ€è¦å°†ç”¨æˆ·æ„å›¾åˆ†ç±»ä¸º `æŸ¥è¯¢ç”¨æˆ·è§’è‰²` æˆ–è€… `æä¾›ç”¨æˆ·è§’è‰²ä¿¡æ¯` æˆ–è€… `å…¶ä»–`ã€‚
        å¦‚æœç”¨æˆ·éœ€è¦å¸®åŠ©æŸ¥æ‰¾ä»–ä»¬çš„è§’è‰²ï¼Œè¯·ä½¿ç”¨ {update_user_role_tools[1].name} æ¥æœç´¢ç”¨æˆ·è§’è‰²ã€‚
        å¦‚æœç”¨æˆ·çš„æ„å›¾æ˜¯æä¾›ä»–ä»¬çš„è§’è‰²ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ {update_user_role_tools[0].name} æ¥æ›´æ–°ç”¨æˆ·è§’è‰²ã€‚
        æ‰€æœ‰å…¶ä»–ç”¨æˆ·è¾“å…¥éƒ½åº”è¯¥è¢«åˆ†ç±»ä¸º `å…¶ä»–`ã€‚ä¸ç¡®å®šæ—¶ï¼Œé»˜è®¤ä¸º`å…¶ä»–`ã€‚ä½¿ç”¨ {update_user_role_tools[0].name} å·¥å…·ï¼Œå°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        å¦‚æœç”¨æˆ·æ„å›¾æ˜¯`å…¶ä»–`ï¼Œä½¿ç”¨ {update_user_role_tools[0].name} å·¥å…·ï¼Œå°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        
        ç”¨æˆ·è§’è‰²ä¸ºï¼šä¸“æŠ€ä¸ªäººã€ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨ã€ç»§ç»­æ•™è‚²æœºæ„ã€è·³è¿‡
        æ³¨æ„ï¼šç”¨æˆ·çš„é—®é¢˜å¯èƒ½åŒ…å«è§’è‰²ï¼Œå³ä½¿åŒ…å«è§’è‰²ï¼Œç”¨æˆ·çš„æ„å›¾ä¸ä¸€å®šæ˜¯æä¾›è§’è‰²ä¿¡æ¯ã€‚å› æ­¤ï¼Œå½“åŒ…å«è§’è‰²æ—¶ï¼Œä½ è¦æ›´åŠ å°å¿ƒçš„å¯¹ç”¨æˆ·çš„æ„å›¾è¿›è¡Œåˆ†ç±»ã€‚
        æ³¨æ„ï¼šå½“ç”¨æˆ·æ„å›¾æŸ¥è¯¢ä¿¡æ¯æ˜¯ï¼Œç”¨æˆ·ä¸ä¸€å®šåªä¼šæŸ¥è¯¢è‡ªå·±çš„è§’è‰²ï¼Œä¹Ÿå¯èƒ½æŸ¥è¯¢å…¶ä»–ä¿¡æ¯ã€‚åªæœ‰å½“ç”¨æˆ·æŸ¥è¯¢è§’è‰²æˆ–æ³¨å†Œä¿¡æ¯æ—¶ï¼Œä½ æ‰éœ€è¦ä½¿ç”¨ {update_user_role_tools[1].name} å·¥å…·ã€‚å¦åˆ™ï¼Œä½¿ç”¨ {update_user_role_tools[0].name} å·¥å…·ï¼Œå°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        
        æœ€ç»ˆè¿”å›éœ€è¦è°ƒç”¨çš„å·¥å…·åç§°å’Œè¾“å…¥ã€‚è¿”å›çš„å“åº”åº”è¯¥æ˜¯ä¸€ä¸ª JSON æ•°æ®ï¼Œå…¶ä¸­åŒ…å« 'name' å’Œ 'arguments' é”®ã€‚'argument' çš„å€¼åº”è¯¥æ˜¯ä¸€ä¸ª jsonï¼Œå…¶ä¸­åŒ…å«è¦ä¼ é€’ç»™å·¥å…·çš„è¾“å…¥ã€‚

        ### ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š
        #### æŸ¥è¯¢ç”¨æˆ·è§’è‰²:
        - "æˆ‘æƒ³çŸ¥é“æˆ‘çš„æ³¨å†ŒçŠ¶æ€" -> è°ƒç”¨ {update_user_role_tools[1].name}, å°† 'arguments' ä¸­çš„ 'user_id_number' è®¾ç½®ä¸º 'unknown'ã€‚
        - "ä¸çŸ¥é“å•Šï¼Œå¸®æˆ‘æŸ¥ä¸€ä¸‹" -> è°ƒç”¨ {update_user_role_tools[1].name}, å°† 'arguments' ä¸­çš„ 'user_id_number' è®¾ç½®ä¸º 'unknown'ã€‚
        - "å±±ä¸œçœæµå—å¸‚ä¸­å¿ƒåŒ»é™¢" -> è°ƒç”¨ {update_user_role_tools[1].name}, å°† 'arguments' ä¸­çš„ 'user_id_number' è®¾ç½®ä¸º 'å±±ä¸œçœæµå—å¸‚ä¸­å¿ƒåŒ»é™¢'ã€‚
        - "æµå®å¸‚äººæ‰æœåŠ¡ä¸­å¿ƒ" -> è°ƒç”¨ {update_user_role_tools[1].name}, å°† 'arguments' ä¸­çš„ 'user_id_number' è®¾ç½®ä¸º 'æµå®å¸‚äººæ‰æœåŠ¡ä¸­å¿ƒ'ã€‚
        - "43942929391938222" -> è°ƒç”¨ {update_user_role_tools[1].name}, å°† 'arguments' ä¸­çš„ 'user_id_number' è®¾ç½®ä¸º '43942929391938222'ã€‚
        
        #### æä¾›ç”¨æˆ·è§’è‰²ä¿¡æ¯:
        - "æˆ‘æ˜¯ä¸“æŠ€ä¸ªäºº" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        - "ä¸“æŠ€ä¸ªäºº" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'ä¸“æŠ€ä¸ªäºº'ã€‚
        - "ç”¨äººå•ä½" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'ç”¨äººå•ä½'ã€‚
        - "ä¸»ç®¡éƒ¨é—¨" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'ä¸»ç®¡éƒ¨é—¨'ã€‚
        - "ç»§ç»­æ•™è‚²æœºæ„" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'ç»§ç»­æ•™è‚²æœºæ„'ã€‚
        - "è·³è¿‡" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'è·³è¿‡'ã€‚
        
        #### å…¶ä»–
        - "ç»§ç»­æ•™è‚²æœºæ„å¦‚ä½•æ³¨å†Œ" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        - "æ³¨å†Œå¦‚ä½•å®¡æ ¸" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        - "ä¸“æŠ€ä¸ªäººæ³¨å†Œå¦‚ä½•å®¡æ ¸" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        - "å•ä½æ€ä¹ˆå­¦æ—¶ç”³æŠ¥" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚
        - "å•ä½çš„åŸ¹è®­è®¡åˆ’æ€ä¹ˆå®¡æ ¸" -> è°ƒç”¨ {update_user_role_tools[0].name}, å°† 'arguments' ä¸­çš„ 'user_role' è®¾ç½®ä¸º 'unknown'ã€‚

        """,
        qa_map_path = "./policies_v2/jining_qa_map.json"
        # summarization_llm=summarization_llm,
        # summarization_llm_prompt=summarization_llm_prompt,
)


def check_role_qa_router(info):
    print(info["topic"])
    if "unknown" in info["topic"]["output"].lower():
        print("check role entering unknown")
        # return update_user_role_chain_executor
        return update_user_role_agent
    elif "ä¸“æŠ€ä¸ªäºº" in info["topic"]["output"].lower():
        print("entering ä¸“æŠ€ä¸ªäºº")
        return individual_qa_agent_executor_v2
    elif "ç”¨äººå•ä½" in info["topic"]["output"].lower():
        print("entering ç”¨äººå•ä½")
        return employing_unit_qa_agent_executor_v2
    elif "ä¸»ç®¡éƒ¨é—¨" in info["topic"]["output"].lower():
        print("entering ä¸»ç®¡éƒ¨é—¨")
        return supervisory_department_qa_agent_executor_v2
    elif "ç»§ç»­æ•™è‚²æœºæ„" in info["topic"]["output"].lower():
        print("entering ç»§ç»­æ•™è‚²æœºæ„")
        return cont_edu_qa_agent_executor_v2
    print("é»˜è®¤è¿›å…¥ä¸“æŠ€ä¸ªäºº")
    return individual_qa_agent_executor_v2


def check_user_role(inputs):
    template = main_qa_agent_executor.agent.runnable.get_prompts()[0].template.lower()
    # print(template)
    start_index = template.find("current user role is") + len("current user role is")
    end_index = template.find("\n", start_index)
    result = template[start_index:end_index].strip()
    # result = st.session_state.get("user_role", "unknown")
    inputs["output"] = result
    return inputs


# check_user_role_agent = create_atomic_retriever_agent(tools=[CheckUserRoleTool(), RegistrationStatusToolIndividual()])


check_user_role_chain = RunnableLambda(check_user_role)

qa_chain_v2 = {
    "topic": check_user_role_chain,
    "input": lambda x: x["input"], #?
} | RunnableLambda(check_role_qa_router)

# ç™»å½•é—®é¢˜å’¨è¯¢
login_problem_classifier_prompt = PromptTemplate.from_template(
    """Given the user input AND chat history below, classify whether the conversation topic or user mentioned being about `æ²¡æœ‰æ»‘å—` or `å¯†ç é”™è¯¯` or `è´¦å·ä¸å­˜åœ¨` or `å®¡æ ¸ä¸­` or `æ‰‹æœºç½‘é¡µæ— æ³•ç™»å½•` or `é¡µé¢ä¸å…¨` or `æ— æ³•ç™»å½•` or `éªŒè¯å¤±è´¥`

# Do not answer the question. Simply classify it as being related to `æ²¡æœ‰æ»‘å—` or `å¯†ç é”™è¯¯` or `è´¦å·ä¸å­˜åœ¨` or `å®¡æ ¸ä¸­` or `æ‰‹æœºç½‘é¡µæ— æ³•ç™»å½•` or `é¡µé¢ä¸å…¨` or `æ— æ³•ç™»å½•` or `éªŒè¯å¤±è´¥`
# Do not respond with anything other than `æ²¡æœ‰æ»‘å—` or `å¯†ç é”™è¯¯` or `è´¦å·ä¸å­˜åœ¨` or `å®¡æ ¸ä¸­` or `æ‰‹æœºç½‘é¡µæ— æ³•ç™»å½•` or `é¡µé¢ä¸å…¨` or `æ— æ³•ç™»å½•` or `éªŒè¯å¤±è´¥`

{chat_history}
Question: {input}

# Classification:"""
)

login_problem_classifier_prompt.input_variables = ["input", "chat_history"]

login_problem_classifier_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)

login_problem_classifier_chain = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=login_problem_classifier_prompt,
    memory=login_problem_classifier_memory,
    verbose=True,
)

# login_problem_agent_executor = create_react_agent_with_memory(
#     tools=[login_problems_detail_tool]
# )

login_problem_agent_executor = create_atomic_retriever_agent_single_tool_qa_map(
    login_problems_detail_tool, 
    qa_map_path = "./policies_v2/login_problems_details_qa_map.json")

login_problem_ask_user_executor = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=PromptTemplate.from_template(
        """Your ONLY job is to say: è¯·é—®æ‚¨æ— æ³•ç™»å½•æˆ–ç™»å½•ä¸ä¸Šï¼Œæç¤ºæ˜¯ä»€ä¹ˆï¼Ÿ

You may use different words to ask the same question. But do not answer anything other than asking the user to provide more information.
                                                                                                    
Begin!
"""
    ),
    verbose=True,
    output_key="output",
)


def login_problem_router(info):
    print(info["topic"])
    if "æ²¡æœ‰æ»‘å—" in info["topic"]["text"]:
        print("æ²¡æœ‰æ»‘å—")
        return login_problem_agent_executor
    elif "å¯†ç é”™è¯¯" in info["topic"]["text"]:
        print("å¯†ç é”™è¯¯")
        return login_problem_agent_executor
    elif "è´¦å·ä¸å­˜åœ¨" in info["topic"]["text"]:
        print("è´¦å·ä¸å­˜åœ¨")
        return login_problem_agent_executor
    elif "å®¡æ ¸ä¸­" in info["topic"]["text"]:
        print("å®¡æ ¸ä¸­")
        return login_problem_agent_executor
    elif "æ‰‹æœºç½‘é¡µæ— æ³•ç™»å½•" in info["topic"]["text"]:
        print("æ‰‹æœºç½‘é¡µæ— æ³•ç™»å½•")
        return login_problem_agent_executor
    elif "é¡µé¢ä¸å…¨" in info["topic"]["text"]:
        print("é¡µé¢ä¸å…¨")
        return login_problem_agent_executor
    elif "éªŒè¯å¤±è´¥" in info["topic"]["text"]:
        print("é¡µé¢ä¸å…¨")
        return login_problem_agent_executor
    elif "æ— æ³•ç™»å½•" in info["topic"]["text"]:
        print("æ— æ³•ç™»å½•")
        return login_problem_ask_user_executor

    return login_problem_ask_user_executor


login_problem_chain = {
    "topic": login_problem_classifier_chain,
    "input": lambda x: x["input"],
} | RunnableLambda(login_problem_router)


# å¿˜è®°å¯†ç é—®é¢˜å’¨è¯¢
forgot_password_classifier_prompt = PromptTemplate.from_template(
    """Given the user input AND chat history below, classify whether the conversation topic or user mentioned being about `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æ‰‹æœºå·` or `ä¿¡æ¯æœ‰è¯¯` or `ä¿å­˜ä¸äº†` or `æ”¹å¯†ç æ€ä¹ˆä¸è¡Œ`

# Do not answer the question. Simply classify it as being related to `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æ‰‹æœºå·` or `ä¿¡æ¯æœ‰è¯¯` or `ä¿å­˜ä¸äº†` or `æ”¹å¯†ç æ€ä¹ˆä¸è¡Œ`
# Do not respond with anything other than `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æ‰‹æœºå·` or `ä¿¡æ¯æœ‰è¯¯` or `ä¿å­˜ä¸äº†` or `æ”¹å¯†ç æ€ä¹ˆä¸è¡Œ`

{chat_history}
Question: {input}

# Classification:"""
)

forgot_password_classifier_prompt.input_variables = ["input", "chat_history"]
forgot_password_classifier_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)
forgot_password_classifier_chain = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=forgot_password_classifier_prompt,
    memory=forgot_password_classifier_memory,
    verbose=True,
)

# forgot_password_agent_executor = create_react_agent_with_memory(
#     tools=[forgot_password_tool]
# )

forgot_password_agent_executor = create_atomic_retriever_agent_single_tool_qa_map(
    forgot_password_tool, 
    qa_map_path = "./policies_v2/forgot_password_qa_map.json")

forgot_password_ask_user_executor = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=PromptTemplate.from_template(
        """Your ONLY job is to say: æ‚¨å¯ä»¥åœ¨å¹³å°é¦–é¡µå³ä¾§â€”â€”ã€ç™»å½•ã€‘æŒ‰é’®å³ä¸Šæ–¹ â€”â€”ç‚¹å‡»ã€å¿˜è®°å¯†ç ï¼Ÿã€‘æ‰¾å›å¯†ç ã€‚
do not answer anything other than asking the user to provide more information.
                                                                                                    
Begin!
"""
    ),
    verbose=True,
    output_key="output",
)


def forgot_password_router(info):
    print(info["topic"])
    if "å¿˜è®°å¯†ç " in info["topic"]["text"]:
        print("å¿˜è®°å¯†ç ")
        return forgot_password_agent_executor
    elif "æ‰¾å›å¯†ç " in info["topic"]["text"]:
        print("æ‰¾å›å¯†ç ")
        return forgot_password_agent_executor
    elif "æ‰‹æœºå·" in info["topic"]["text"]:
        print("æ‰‹æœºå·")
        return forgot_password_agent_executor
    elif "ä¿¡æ¯æœ‰è¯¯" in info["topic"]["text"]:
        print("ä¿¡æ¯æœ‰è¯¯")
        return forgot_password_agent_executor
    elif "ä¿å­˜ä¸äº†" in info["topic"]["text"]:
        print("ä¿å­˜ä¸äº†")
        return forgot_password_agent_executor
    elif "æ”¹å¯†ç æ€ä¹ˆä¸è¡Œ" in info["topic"]["text"]:
        print("æ”¹å¯†ç æ€ä¹ˆä¸è¡Œ")
        return forgot_password_agent_executor
    return forgot_password_ask_user_executor


forgot_password_chain = {
    "topic": forgot_password_classifier_chain,
    "input": lambda x: x["input"],
} | RunnableLambda(forgot_password_router)

# æŸ¥è¯¢æ³¨å†Œä¿¡æ¯


# æµå®å¸‚
# jining_agent_executor = create_react_agent_with_memory(tools=[jn_city_tool])
jining_agent_executor = create_atomic_retriever_agent_single_tool_qa_map(
    jn_city_tool, 
    qa_map_path = "./policies_v2/jining_qa_map.json")

# When user input a number longer than 6 digits, use it as user id number in the context for the tool.
# When the user input a four-digit number, use it as year in the context for the tool.
# å­¦æ—¶ä¸æ˜¾ç¤ºç­‰é—®é¢˜
credit_problem_prompt = PromptTemplate.from_template(
    """Use a tool to answer the user's qustion.

You MUST use a tool and generate a response based on tool's output.
DO NOT hallucinate!!!! DO NOT Assume any user inputs. ALWAYS ask the user for more information if needed.

Note that you may need to translate user inputs. Here are a few examples for translating user inputs:
- user: "å…¬éœ€", output: "å…¬éœ€è¯¾"
- user: "å…¬", output: "å…¬éœ€è¯¾"
- user: "ä¸“ä¸š", output: "ä¸“ä¸šè¯¾"
- user: "ä¸“", output: "ä¸“ä¸šè¯¾"
- user: "19å¹´", output: "2019"
- user: "19", output: "2019"
- user: "2019å¹´â€, output: "2019"


user location: unknown

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
)
credit_problem_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
    "chat_history",
]

credit_problem_tools = [CheckUserCreditTool()]
credit_problem_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)
credit_problem_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    # ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3),
    credit_problem_tools,
    credit_problem_prompt,
)
credit_problem_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=credit_problem_chain,
    tools=credit_problem_tools,
    memory=credit_problem_memory,
    verbose=True,
    handle_parsing_errors=True,
)

# update user location agent
update_user_location_agent = create_single_function_call_agent(UpdateUserLocTool2())


def check_user_loc_and_route(info):
    print(info["topic"])
    if "unknown" in info["topic"]["output"].lower():
        print("entering update_user_location_chain_executor")
        # return update_user_location_chain_executor
        return update_user_location_agent
    print("entering credit_problem_chain")
    return credit_problem_chain_executor
    # return main_credit_problem_agent


def check_user_loc(inputs):
    template = credit_problem_chain_executor.agent.runnable.get_prompts()[
        0
    ].template.lower()
    # print(template)
    start_index = template.find("user location: ") + len("user location: ")
    end_index = template.find("\n", start_index)
    result = template[start_index:end_index].strip()
    # result = st.session_state.get("user_role", "unknown")
    inputs["output"] = result
    return inputs

check_loc_chain = RunnableLambda(check_user_loc)

main_credit_problem_chain = {
    "topic": check_loc_chain,
    "input": lambda x: x["input"],
} | RunnableLambda(check_user_loc_and_route)

# course progress
course_progress_problems_prompt = PromptTemplate.from_template(
    """Answer the user's question step by step. Don't give the whole answer at once. Guide the user to the solution.

Always start with Step 1 below, DO NOT go to Step 2. Only execute Step 1 first. Do Not include the keyword `Step 1` or `Step 2` in your response.

Step 1. First check the user's learning method belongs to ç”µè„‘æµè§ˆå™¨ or æ‰‹æœºå¾®ä¿¡æ‰«ç 

Step 2. Based on the user's choice in Step 1,
If the user's learning method belongs to ç”µè„‘æµè§ˆå™¨ or æ‰‹æœºå¾®ä¿¡æ‰«ç , then say ç”µè„‘æµè§ˆå™¨è¯·ä¸è¦ä½¿ç”¨IEã€edgeç­‰è‡ªå¸¦æµè§ˆå™¨ï¼Œå¯ä»¥ä½¿ç”¨æœç‹—ã€è°·æ­Œã€360æµè§ˆå™¨æé€Ÿæ¨¡å¼ç­‰æµè§ˆå™¨è¯•è¯•ã€‚
Otherwise, say ç›®å‰æ”¯æŒçš„å­¦ä¹ æ–¹å¼æ˜¯ç”µè„‘æµè§ˆå™¨æˆ–è€…æ‰‹æœºå¾®ä¿¡æ‰«ç ä¸¤ç§ï¼Œå»ºè®®æ‚¨å†ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼è¯•è¯•
If the user's used the right method but still has problems, then say å»ºè®®æ¸…é™¤æµè§ˆå™¨æˆ–è€…å¾®ä¿¡ç¼“å­˜å†è¯•è¯•
If the user used the right method and æ¸…é™¤äº†ç¼“å­˜, then sayï¼ŒæŠ±æ­‰ï¼Œæ‚¨çš„é—®é¢˜æ¶‰åŠåˆ°æµ‹è¯•ï¼Œå»ºè®®æ‚¨è”ç³»å¹³å°çš„äººå·¥çƒ­çº¿å®¢æœæˆ–è€…åœ¨çº¿å®¢æœè¿›è¡Œåé¦ˆ

{chat_history}
Question: {input}
"""
)
course_progress_problems_prompt.input_variables = [
    "input",
    "chat_history",
]
course_progress_problems_llm = Tongyi(
    model_name="qwen-max", model_kwargs={"temperature": 0.3}
)
course_progress_problems_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input", return_messages=True
)
course_progress_problems_llm_chain = LLMChain(
    llm=course_progress_problems_llm,
    memory=course_progress_problems_memory,
    prompt=course_progress_problems_prompt,
    verbose=True,
    output_key="output",
)


# multiple login
multiple_login_prompt = PromptTemplate.from_template(
    """Answer the user's question step by step. Don't give the whole answer at once. Guide the user to the solution.

Always start with Step 1 below, DO NOT go to Step 2. Only execute Step 1 first. Do Not include the keyword `Step 1` or `Step 2` in your response.

Step 1
First check the user's learning method belongs to ç”µè„‘æµè§ˆå™¨ or æ‰‹æœºå¾®ä¿¡æ‰«ç 

Step 2
Based on the user's choice in Step 1,
If the user's learning method belongs to ç”µè„‘æµè§ˆå™¨ or æ‰‹æœºå¾®ä¿¡æ‰«ç , then say è¯·å‹¿ä½¿ç”¨ç”µè„‘å’Œæ‰‹æœºåŒæ—¶ç™»å½•è´¦å·å­¦ä¹ ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ç”µè„‘æˆ–æ‰‹æœºåŒæ—¶ç™»å½•å¤šäººè´¦å·å­¦ä¹ ã€‚
If the user say æ²¡æœ‰ç™»å½•å¤šä¸ªè´¦å·/æ²¡æœ‰åŒæ—¶ç™»å½• etc., say å»ºè®®æ‚¨æ¸…é™¤ç”µè„‘æµè§ˆå™¨æˆ–æ‰‹æœºå¾®ä¿¡ç¼“å­˜ï¼Œå¹¶ä¿®æ”¹å¹³å°ç™»å½•å¯†ç åé‡æ–°ç™»å½•å­¦ä¹ è¯•è¯•ã€‚

Answer the question in Chinese.

{chat_history}
Question: {input}
"""
)
multiple_login_prompt.input_variables = [
    "input",
    "chat_history",
]
multiple_login_llm = Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3})
multiple_login_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input", return_messages=True
)
multiple_login_llm_chain = LLMChain(
    llm=multiple_login_llm,
    memory=multiple_login_memory,
    prompt=multiple_login_prompt,
    verbose=True,
    output_key="output",
)


# how to register class
# register_class_prompt = PromptTemplate.from_template(
#     """Answer the user's question step by step. Don't give the whole answer at once. Guide the user to the solution.

# Always start with Step 1 below, DO NOT go to Step 2. Only execute Step 1 first. Do Not include the keyword `Step 1` or `Step 2` in your response.

# Step 1. First kindly ask the user whether they want to register å…¬éœ€è¯¾ or ä¸“ä¸šè¯¾

# Step 2. Based on the user's choice in Step 1,
# If the user wants å…¬éœ€è¯¾, then say é€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©å¯¹åº”å¹´åº¦çš„è¯¾ç¨‹æŠ¥åå­¦ä¹ å°±å¯ä»¥ã€‚å¦‚æœæœ‰è€ƒè¯•ï¼Œéœ€è¦è€ƒè¯•é€šè¿‡åæ‰èƒ½è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ã€‚
# If the user wants ä¸“ä¸šè¯¾, say é€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©ä¸æ‚¨èŒç§°ä¸“ä¸šç›¸ç¬¦æˆ–è€…ç›¸å…³çš„è¯¾ç¨‹è¿›è¡ŒæŠ¥åï¼Œç¼´è´¹åå¯ä»¥å­¦ä¹ ã€‚ä¸“ä¸šè¯¾å­¦å®Œå°±å¯ä»¥è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ï¼Œæ— éœ€è€ƒè¯•ã€‚
# If the user wants both, then say å¦‚æœè¦æŠ¥åå…¬éœ€è¯¾ï¼Œé€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©å¯¹åº”å¹´åº¦çš„è¯¾ç¨‹æŠ¥åå­¦ä¹ å°±å¯ä»¥ã€‚å¦‚æœæœ‰è€ƒè¯•ï¼Œéœ€è¦è€ƒè¯•é€šè¿‡åæ‰èƒ½è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ã€‚å¦‚æœè¦æŠ¥åä¸“ä¸šè¯¾ï¼Œé€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©ä¸æ‚¨èŒç§°ä¸“ä¸šç›¸ç¬¦æˆ–è€…ç›¸å…³çš„è¯¾ç¨‹è¿›è¡ŒæŠ¥åï¼Œç¼´è´¹åå¯ä»¥å­¦ä¹ ã€‚ä¸“ä¸šè¯¾å­¦å®Œå°±å¯ä»¥è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ï¼Œæ— éœ€è€ƒè¯•ã€‚

# Answer the question in Chinese.

# {chat_history}
# Question: {input}
# """
# )

register_class_prompt = PromptTemplate.from_template(
    """åˆ†æ­¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä¸è¦ä¸€æ¬¡æ€§ç»™å‡ºæ‰€æœ‰ç­”æ¡ˆã€‚å¼•å¯¼ç”¨æˆ·è§£å†³å…³äºæŠ¥ç­æŠ¥è¯¾ï¼Œä»¥åŠè´¹ç”¨çš„é—®é¢˜ã€‚

    ## æŠ¥ç­æŠ¥è¯¾åŠè´¹ç”¨æ”¿ç­–
    ### æŠ¥ç­æŠ¥è¯¾çš„ä¿¡æ¯å¦‚ä¸‹ï¼š
    å…¬éœ€è¯¾ -> é€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©å¯¹åº”å¹´åº¦çš„è¯¾ç¨‹æŠ¥åå­¦ä¹ å°±å¯ä»¥ã€‚å¦‚æœæœ‰è€ƒè¯•ï¼Œéœ€è¦è€ƒè¯•é€šè¿‡åæ‰èƒ½è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ã€‚
    ä¸“ä¸šè¯¾ -> é€‰æ‹©ã€æµå®èŒä¸šæŠ€æœ¯å­¦é™¢ã€‘è¿™ä¸ªå¹³å°ï¼Œè¿›å…¥ã€é€‰è¯¾ä¸­å¿ƒã€‘ï¼Œå…ˆé€‰æ‹©ã€åŸ¹è®­å¹´åº¦ã€‘ï¼Œå†é€‰æ‹©ä¸æ‚¨èŒç§°ä¸“ä¸šç›¸ç¬¦æˆ–è€…ç›¸å…³çš„è¯¾ç¨‹è¿›è¡ŒæŠ¥åï¼Œç¼´è´¹åå¯ä»¥å­¦ä¹ ã€‚ä¸“ä¸šè¯¾å­¦å®Œå°±å¯ä»¥è®¡å…¥å¯¹åº”å¹´åº¦çš„å­¦æ—¶ï¼Œæ— éœ€è€ƒè¯•ã€‚
    
    ### æŠ¥ç­æŠ¥è¯¾çš„è´¹ç”¨å¦‚ä¸‹ï¼š
    å…¬éœ€è¯¾ï¼šç»å½“åœ°äººç¤¾è§„å®šè¦æ±‚ï¼Œå…¬éœ€è¯¾å…è´¹
    ä¸“ä¸šè¯¾ï¼šç»å½“åœ°äººç¤¾è§„å®šè¦æ±‚ï¼Œä¸“ä¸šè¯¾ä»·æ ¼ä¸º1å…ƒ1å­¦æ—¶

    ### ä¼˜æƒ 
    æŠ±æ­‰ï¼Œè¯¾ç¨‹ä»·æ ¼æ˜¯æ ¹æ®äººç¤¾è¦æ±‚è®¾å®šï¼Œæ²¡æœ‰ä¼˜æƒ æ”¿ç­–ï¼Œéœ€æŒ‰ç…§è¯¾ç¨‹æ ‡å®šçš„ä»·æ ¼è´­ä¹°ã€‚

    ### é›†ä½“ç¼´è´¹
    é›†ä½“æŠ¥ç­æäº¤åéœ€è¦äººå·¥å®¡æ ¸ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ŒåŠæ—¶å…³æ³¨å®¡æ ¸æƒ…å†µã€‚
    é›†ä½“ç¼´è´¹é€€è´¹éœ€è¦äººå·¥å¤„ç†ï¼Œè¯·å°†æ”¯ä»˜æˆªå›¾ã€é€€æ¬¾åŸå› å‘é€åˆ°æˆ‘æ–¹é‚®ç®±ï¼Œé‚®ç®±å·ä¸ºï¼šsdzjkf@163.comï¼Œè¯·åŠæ—¶å…³æ³¨é‚®ç®±å›å¤å¹¶æŒ‰ç…§è¦æ±‚æä¾›ç›¸å…³ä¿¡æ¯ã€‚
    é›†ä½“ç¼´è´¹æ¢å¡æ”¯ä»˜éœ€è¦äººå·¥å¤„ç†ï¼Œè¯·å°†æ‚¨æ”¯ä»˜çš„å¸¦å•†æˆ·å•å·çš„æˆªå›¾ã€é‡‘é¢ä¸¤ä¸ªä¿¡æ¯å‘é€åˆ°æˆ‘æ–¹é‚®ç®±ï¼Œé‚®ç®±å·ä¸ºï¼šsdzjkf@163.comï¼Œç­‰å¾…1-3ä¸ªå·¥ä½œæ—¥åï¼Œæ‚¨ç›´æ¥ç‚¹å‡»â€œæ¢å¡æ”¯ä»˜â€æŒ‰é’®ï¼Œå¾®ä¿¡ç«‹å³æ”¯ä»˜å³å¯ã€‚æ”¯ä»˜å®Œæˆä¹‹åä¸Šä¸€ç¬”è®¢å•çš„è´¹ç”¨è‡ªåŠ¨é€€æ¬¾ã€‚

    ### æµå®å¸‚é«˜çº§èŒä¸šå­¦æ ¡/å±±ä¸œç†å·¥èŒä¸šå­¦é™¢/å¾®å±±å¿äººæ°‘åŒ»é™¢æ€ä¹ˆæŠ¥åè¯¾ç¨‹ï¼Ÿ
    æŠ±æ­‰ï¼Œæˆ‘ä»¬åªè´Ÿè´£æµå®èŒä¸šæŠ€æœ¯å­¦é™¢è¿™ä¸ªåŸ¹è®­å¹³å°ï¼Œå…¶ä»–åŸ¹è®­å­¦æ ¡è¿›å…¥å…·ä½“çš„åŸ¹è®­å¹³å°è¿›è¡Œå’¨è¯¢
    
    ## æŒ‡å—ï¼š
    æ°¸è¿œä»ä¸‹é¢çš„ç¬¬1æ­¥å¼€å§‹ï¼Œä¸è¦ç›´æ¥è·³åˆ°ç¬¬2æ­¥ã€‚åœ¨å›ç­”ä¸­ä¸è¦åŒ…å«å…³é”®å­— `ç¬¬1æ­¥` æˆ– `ç¬¬2æ­¥`ã€‚

    ç¬¬1æ­¥. é¦–å…ˆè¯¢é—®ç”¨æˆ·æ˜¯å¦è¦æ³¨å†Œ å…¬éœ€è¯¾ or ä¸“ä¸šè¯¾

    ç¬¬2æ­¥. æ ¹æ®ç”¨æˆ·åœ¨ç¬¬1æ­¥ä¸­çš„é€‰æ‹©ï¼Œåœ¨æŠ¥ç­æŠ¥è¯¾åŠè´¹ç”¨æ”¿ç­–ä¸­ï¼Œé€‰æ‹©æœ€ç›¸å…³çš„å›ç­”ã€‚
    å¦‚æœç”¨æˆ·æƒ³è¦ å…¬éœ€è¯¾, åˆ™åªå›ç­”å…¬éœ€è¯¾ç›¸å…³çš„ä¿¡æ¯
    å¦‚æœç”¨æˆ·æƒ³è¦ ä¸“ä¸šè¯¾, åˆ™åªå›ç­”ä¸“ä¸šè¯¾ç›¸å…³çš„ä¿¡æ¯
    å¦‚æœç”¨æˆ·éƒ½æƒ³äº†è§£ï¼Œåˆ™å°†ä¸¤ä¸ªå›ç­”éƒ½æä¾›ã€‚

    ### æ³¨æ„ï¼š
    åœ¨è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦æ³¨å†Œ å…¬éœ€è¯¾ or ä¸“ä¸šè¯¾ å‰ï¼Œä¸è¦ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å§‹ç»ˆå¼•å¯¼ç”¨æˆ·è§£å†³é—®é¢˜ã€‚
    è¯·ä¿æŒå›ç­”ç®€æ´ï¼Œç›´æ¥ã€‚å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”é—®é¢˜

{chat_history}
é—®é¢˜: {input}
"""
)

register_class_prompt.input_variables = [
    "input",
    "chat_history",
]
register_class_llm = Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3})
register_class_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input", return_messages=True
)
register_class_llm_chain = LLMChain(
    llm=register_class_llm,
    memory=register_class_memory,
    prompt=register_class_prompt,
    verbose=True,
    output_key="output",
)

# refund agent
refund_prompt = PromptTemplate.from_template(
    """Use a tool to answer the user's qustion.

Ask the user to provide èº«ä»½è¯å·ï¼Œin order to æŸ¥è¯¢è¯¾ç¨‹ä¿¡æ¯
You MUST use a tool and generate a response based on tool's output.

When user input a number longer than 6 digits, use it as user èº«ä»½è¯å· in the context for the tool.
DO NOT hallucinate!!!! 

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
)
# refund_prompt = PromptTemplate.from_template(
#     """ä½¿ç”¨å·¥å…·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

# è¯·åŠ¡å¿…å‘ç”¨æˆ·è¯¢é—® èº«ä»½è¯å·ï¼Œä»¥ä¾¿æŸ¥è¯¢è¯¾ç¨‹ä¿¡æ¯
# ä½ å¿…é¡»ä½¿ç”¨ä½ ä»…æœ‰çš„å·¥å…·å¹¶æ ¹æ®å·¥å…·çš„è¾“å‡ºç”Ÿæˆå¯¹åº”çš„å›ç­”ã€‚

# å½“ç”¨æˆ·è¾“å…¥çš„æ•°å­—è¶…è¿‡6ä½æ—¶ï¼Œè¯·å°†å…¶ä½œä¸ºç”¨æˆ·çš„ èº«ä»½è¯å· ä½¿ç”¨ã€‚
# ä¸è¦å‡­ç©ºæƒ³è±¡ï¼ï¼ï¼ï¼ä¸è¦å‡è®¾ä»»ä½•ç”¨æˆ·è¾“å…¥ã€‚å¦‚æœéœ€è¦ï¼Œè¯·å§‹ç»ˆè¦æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ã€‚

# ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š

# {tools}

# ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

# é—®é¢˜ï¼šä½ å¿…é¡»å›ç­”çš„è¾“å…¥é—®é¢˜
# æ€è€ƒï¼šä½ åº”è¯¥æ€»æ˜¯è€ƒè™‘è¯¥åšä»€ä¹ˆã€‚
# æ“ä½œï¼šè¦æ‰§è¡Œçš„æ“ä½œåº”ä¸º [{tool_names}] ä¸­çš„ä¸€ä¸ª
# æ“ä½œè¾“å…¥ï¼šæ“ä½œçš„è¾“å…¥
# è§‚å¯Ÿï¼šæ“ä½œçš„ç»“æœ
# ...ï¼ˆè¿™ä¸ªæ€è€ƒ/æ“ä½œ/æ“ä½œè¾“å…¥/è§‚å¯Ÿå¯ä»¥é‡å¤ N æ¬¡ï¼‰
# æ€è€ƒï¼šæˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆ
# æœ€ç»ˆç­”æ¡ˆï¼šåŸå§‹è¾“å…¥é—®é¢˜çš„æœ€ç»ˆç­”æ¡ˆ

# å¼€å§‹ï¼

# {chat_history}
# é—®é¢˜: {input}
# æ€è€ƒ:{agent_scratchpad}
# """
# )
refund_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
    "chat_history",
]

refund_tools = [RefundTool()]
refund_memory = ConversationBufferMemory(memory_key="chat_history", input_key="input")
refund_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    # ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3),
    refund_tools,
    refund_prompt,
)
refund_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=refund_chain,
    tools=refund_tools,
    memory=refund_memory,
    verbose=True,
    handle_parsing_errors=True,
)

# cannot find course agent
cannot_find_course_prompt = PromptTemplate.from_template(
    """Use a tool to answer the user's qustion.

Ask the user to provide èº«ä»½è¯å·ï¼Œin order to æ£€æŸ¥ç”¨æˆ·è´­ä¹°è¯¾ç¨‹è®°å½•
You MUST use a tool and generate a response based on tool's output.

When user input a number longer than 6 digits, use it as user èº«ä»½è¯å· in the context for the tool.
DO NOT hallucinate!!!! 

You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Answer the question in Chinese.

{chat_history}
Question: {input}
Thought:{agent_scratchpad}
"""
)
cannot_find_course_prompt.input_variables = [
    "agent_scratchpad",
    "input",
    "tool_names",
    "tools",
    "chat_history",
]

cannot_find_course_tools = [CheckPurchaseTool()]
cannot_find_course_memory = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)
cannot_find_course_chain = create_react_agent(
    Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    # ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3),
    cannot_find_course_tools,
    cannot_find_course_prompt,
)
cannot_find_course_chain_executor = AgentExecutor.from_agent_and_tools(
    agent=cannot_find_course_chain,
    tools=cannot_find_course_tools,
    memory=cannot_find_course_memory,
    verbose=True,
    handle_parsing_errors=True,
)


# MAIN ENTRY POINT
# main_question_classifier_template = """Given the user input AND the user input history below, classify whether the conversation topic or user mentioned being about `å­¦æ—¶æ²¡æ˜¾ç¤º` or `å­¦æ—¶æœ‰é—®é¢˜` or `æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å` or `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦` or `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•` or `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†` or `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†` or `æ— æ³•ç™»å½•` or `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æµå®å¸‚` or `æ³¨å†Œ` or `å®¡æ ¸` or `å­¦æ—¶å¯¹æ¥` or `å­¦æ—¶ç”³æŠ¥` or `å­¦æ—¶å®¡æ ¸` or `ç³»ç»Ÿæ“ä½œ` or `ä¿®æ”¹ä¿¡æ¯` or `å…¶ä»–`.

# # Do not answer the question. Simply classify it as being related to `å­¦æ—¶æ²¡æ˜¾ç¤º` or `å­¦æ—¶æœ‰é—®é¢˜` or `æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å` or `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦` or `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•` or `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†` or `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†` or `æ— æ³•ç™»å½•` or `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æµå®å¸‚` or `æ³¨å†Œ` or `å®¡æ ¸` or `å­¦æ—¶å¯¹æ¥` or `å­¦æ—¶ç”³æŠ¥` or `å­¦æ—¶å®¡æ ¸` or `ç³»ç»Ÿæ“ä½œ` or `ä¿®æ”¹ä¿¡æ¯` or `å…¶ä»–`.
# # Do not respond with anything other than `å­¦æ—¶æ²¡æ˜¾ç¤º` or `å­¦æ—¶æœ‰é—®é¢˜` or `æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å` or `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦` or `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•` or `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†` or `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†` or `æ— æ³•ç™»å½•` or `å¿˜è®°å¯†ç ` or `æ‰¾å›å¯†ç ` or `æµå®å¸‚` or `æ³¨å†Œ` or `å®¡æ ¸` or `å­¦æ—¶å¯¹æ¥` or `å­¦æ—¶ç”³æŠ¥` or `å­¦æ—¶å®¡æ ¸` or `ç³»ç»Ÿæ“ä½œ` or `ä¿®æ”¹ä¿¡æ¯` or `å…¶ä»–`.

# Here are a few examples:
# - If the user says "å­¦æ—¶æ²¡æ˜¾ç¤º", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶æœ‰é—®é¢˜", you should classify it as `å­¦æ—¶æœ‰é—®é¢˜`
# - If the user says "å­¦æ—¶æ²¡å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶æ²¡å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶ä¸å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶ä¸å¯¹", you should classify it as `å­¦æ—¶æœ‰é—®é¢˜`
# - If the user says "å­¦æ—¶å¯¹æ¥", you should classify it as `å­¦æ—¶å¯¹æ¥`
# - If the user says "æµå®å¸‚ï¼Œå¦‚ä½•è¡¥å­¦", you should classify it as `æµå®å¸‚`
# - If the user mentions "æµå®å¸‚", you should classify it as related to `æµå®å¸‚`.
# - If the user doesn't mention "æµå®å¸‚", you should NEVER classify it as related to `æµå®å¸‚`


# {chat_history}
# Question: {input}

# Classification:"""

main_question_classifier_template = """æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ input ä»¥åŠå¯¹è¯å†å²è®°å½• chat_historyï¼Œåˆ¤å®šç”¨æˆ·é—®çš„å†…å®¹å±äºä»¥ä¸‹å“ªä¸€ç±»ï¼š `å­¦æ—¶æ²¡æ˜¾ç¤º` æˆ–è€… `å­¦æ—¶æœ‰é—®é¢˜` æˆ–è€… `æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å` æˆ–è€… `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹` æˆ–è€… `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•` æˆ–è€… `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†` æˆ–è€… `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†` æˆ–è€… `æ— æ³•ç™»å½•` æˆ–è€… `å¿˜è®°å¯†ç ` æˆ–è€… `æ‰¾å›å¯†ç ` æˆ–è€… `æµå®å¸‚` æˆ–è€… `æ³¨å†Œ` æˆ–è€… `å®¡æ ¸` æˆ–è€… `å­¦æ—¶å¯¹æ¥` æˆ–è€… `å­¦æ—¶ç”³æŠ¥` æˆ–è€… `å­¦æ—¶å®¡æ ¸` æˆ–è€… `ç³»ç»Ÿæ“ä½œ` æˆ–è€… `ä¿®æ”¹ä¿¡æ¯` æˆ–è€… `å…¶ä»–`.

# ä¸è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä»…æŠŠç”¨æˆ·çš„é—®é¢˜å½’ç±»ä¸º `å­¦æ—¶æ²¡æ˜¾ç¤º` æˆ– `å­¦æ—¶æœ‰é—®é¢˜` æˆ– `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹` æˆ– `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•` æˆ– `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†` æˆ– `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†` æˆ– `æ— æ³•ç™»å½•` æˆ– `å¿˜è®°å¯†ç ` æˆ– `æ‰¾å›å¯†ç ` æˆ– `æµå®å¸‚` æˆ– `æ³¨å†Œ` æˆ– `å®¡æ ¸` æˆ– `å­¦æ—¶å¯¹æ¥` æˆ– `å­¦æ—¶ç”³æŠ¥` æˆ– `å­¦æ—¶å®¡æ ¸` æˆ– `ç³»ç»Ÿæ“ä½œ` æˆ– `ä¿®æ”¹ä¿¡æ¯` æˆ– `å…¶ä»–`.
# ä¸è¦å›ç­”é™¤æ­¤ä¹‹å¤–çš„ä»»ä½•å†…å®¹ã€‚

ä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­ï¼š
- "å­¦æ—¶æ²¡æ˜¾ç¤º" -> åˆ†ç±»ä¸º `å­¦æ—¶æ²¡æ˜¾ç¤º`
- "å­¦æ—¶æœ‰é—®é¢˜" -> åˆ†ç±»ä¸º `å­¦æ—¶æœ‰é—®é¢˜`
- "å­¦æ—¶æ²¡å¯¹æ¥" -> åˆ†ç±»ä¸º `å­¦æ—¶æ²¡æ˜¾ç¤º`
- "å­¦æ—¶æ²¡å¯¹æ¥" -> åˆ†ç±»ä¸º `å­¦æ—¶æ²¡æ˜¾ç¤º`
- "å­¦æ—¶ä¸å¯¹æ¥" -> åˆ†ç±»ä¸º `å­¦æ—¶æ²¡æ˜¾ç¤º`
- "å­¦æ—¶ä¸å¯¹" -> åˆ†ç±»ä¸º `å­¦æ—¶æœ‰é—®é¢˜`
- "å­¦æ—¶å¯¹æ¥" -> åˆ†ç±»ä¸º `å­¦æ—¶å¯¹æ¥`
- "å­¦æ—¶æŠ¥é”™äº†" -> åˆ†ç±»ä¸º `å­¦æ—¶ç”³æŠ¥`
- "å­¦æ—¶ç”³æŠ¥" -> åˆ†ç±»ä¸º `å­¦æ—¶ç”³æŠ¥`
- "æµå®å¸‚ï¼Œå¦‚ä½•è¡¥å­¦" -> åˆ†ç±»ä¸º `æµå®å¸‚`

æ³¨æ„ï¼š
å¦‚æœç”¨æˆ·æåˆ°äº† "æµå®å¸‚"ï¼Œä½ åº”è¯¥å°†å…¶åˆ†ç±»ä¸ºä¸ `æµå®å¸‚` ç›¸å…³ã€‚å¦‚æœç”¨æˆ·æ²¡æœ‰æåˆ° "æµå®å¸‚"ï¼Œä½ ç»å¯¹ä¸èƒ½å°†å…¶åˆ†ç±»ä¸ºä¸ `æµå®å¸‚` ç›¸å…³ã€‚
å¦‚æœç”¨æˆ·æåˆ°äº†ä»¥ä¸‹å…·ä½“çš„æµå®å¸‚é—®é¢˜ï¼Œä½ åº”è¯¥å°†å…¶åˆ†ç±»åˆ°æµå®å¸‚å…·ä½“çš„é—®é¢˜ä¸­ã€‚å…¶ä»–å…·ä½“é—®é¢˜ï¼Œç»Ÿä¸€å½’ç±»ä¸º `æµå®å¸‚`ã€‚
- "æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹" -> åˆ†ç±»ä¸º `æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹`
- "æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•" -> åˆ†ç±»ä¸º `æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•`
- "æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†" -> åˆ†ç±»ä¸º `æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†`
- "æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†" -> åˆ†ç±»ä¸º `æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†`

{chat_history}
Question: {input}

Classification:"""

main_question_classifier_prompt = PromptTemplate(
    input_variables=["input", "chat_history"],
    template=main_question_classifier_template,
)

main_question_classifier_mem = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)

main_question_classifier = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=main_question_classifier_prompt,
    memory=main_question_classifier_mem,
    verbose=True,
)

# - If the user says "å­¦æ—¶æ²¡æ˜¾ç¤º", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶æœ‰é—®é¢˜", you should classify it as `å­¦æ—¶æœ‰é—®é¢˜`
# - If the user says "å­¦æ—¶æ²¡å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶æ²¡å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶ä¸å¯¹æ¥", you should classify it as `å­¦æ—¶æ²¡æ˜¾ç¤º`
# - If the user says "å­¦æ—¶ä¸å¯¹", you should classify it as `å­¦æ—¶æœ‰é—®é¢˜`
# - If the user says "å­¦æ—¶å¯¹æ¥", you should classify it as `å­¦æ—¶å¯¹æ¥`
# - If the user says "æµå®å¸‚ï¼Œå¦‚ä½•è¡¥å­¦", you should classify it as `æµå®å¸‚`
# - If the user mentions "æµå®å¸‚", you should classify it as related to `æµå®å¸‚`.
# - If the user doesn't mention "æµå®å¸‚", you should NEVER classify it as related to `æµå®å¸‚`

intent_classifier_template = """ç»™å®šç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­ç”¨æˆ·çš„ç›®çš„æ˜¯å¦æ˜¯æä¾›ç”¨æˆ·è§’è‰²ä¿¡æ¯ï¼Œå›ç­” `æ˜¯` æˆ– `å¦`ã€‚

ä¸è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä»…æŠŠç”¨æˆ·çš„é—®é¢˜å½’ç±»ä¸º `æ˜¯` æˆ– `å¦`ã€‚ä¸è¦å›ç­”é™¤æ­¤ä¹‹å¤–çš„ä»»ä½•å†…å®¹ã€‚

ç”¨æˆ·è§’è‰²ä¸ºï¼šä¸“æŠ€ä¸ªäººã€ç”¨äººå•ä½ã€ä¸»ç®¡éƒ¨é—¨ã€ç»§ç»­æ•™è‚²æœºæ„ã€è·³è¿‡

æ³¨æ„ï¼šç”¨æˆ·çš„é—®é¢˜å¯èƒ½åŒ…å«è§’è‰²ï¼Œå³ä½¿åŒ…å«è§’è‰²ï¼Œç”¨æˆ·çš„æ„å›¾ä¸ä¸€å®šæ˜¯æä¾›è§’è‰²ä¿¡æ¯ã€‚å› æ­¤ï¼Œå½“åŒ…å«è§’è‰²æ—¶ï¼Œä½ è¦æ›´åŠ å°å¿ƒçš„å¯¹ç”¨æˆ·çš„æ„å›¾è¿›è¡Œåˆ†ç±»ã€‚

# ä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­ï¼š

é—®é¢˜: {input}

Classification:"""

intent_classifier_prompt = PromptTemplate(
    input_variables=["input", "chat_history"],
    template=intent_classifier_template,
)

intent_classifier_mem = ConversationBufferMemory(
    memory_key="chat_history", input_key="input"
)

intent_classifier = LLMChain(
    llm=Tongyi(model_name="qwen-max", model_kwargs={"temperature": 0.3}),
    prompt=intent_classifier_prompt,
    memory=intent_classifier_mem,
    verbose=True,
)


if "topic" not in st.session_state:
    st.session_state.topic = None


def main_question_classifier_and_route(info):
    print(info)
    if st.session_state.topic is None:
        st.session_state.topic = info["topic"]["text"]
    else:
        info["topic"]["text"] = st.session_state.topic
    if "å­¦æ—¶æ²¡æ˜¾ç¤º" in info["topic"]["text"]:
        print("å­¦æ—¶æ²¡æ˜¾ç¤º")
        return main_credit_problem_chain
        # return test_chain
    if "å­¦æ—¶æœ‰é—®é¢˜" in info["topic"]["text"]:
        print("å­¦æ—¶æœ‰é—®é¢˜")
        return main_credit_problem_chain
    # if "æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å" in info["topic"]["text"]:
    #     print("æµå®å¸‚ï¼šå¦‚ä½•æŠ¥ç­ã€æŠ¥å")
    #     return register_class_llm_chain

    if "æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹" in info["topic"]["text"]:
        print("æµå®å¸‚ï¼šè¯¾ç¨‹è¿›åº¦ä¸å¯¹")
        return course_progress_problems_llm_chain
    if "æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•" in info["topic"]["text"]:
        print("æµå®å¸‚ï¼šå¤šä¸ªè®¾å¤‡ï¼Œå…¶ä»–åœ°æ–¹ç™»å½•")
        return multiple_login_llm_chain
    if "æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†" in info["topic"]["text"]:
        print("æµå®å¸‚ï¼šè¯¾ç¨‹é€€æ¬¾é€€è´¹ï¼Œè¯¾ç¨‹ä¹°é”™äº†")
        return refund_chain_executor
        # return refund_full_chain
    if "æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†" in info["topic"]["text"]:
        print("æµå®å¸‚ï¼šè¯¾ç¨‹æ‰¾ä¸åˆ°ï¼Œè¯¾ç¨‹æ²¡æœ‰äº†")
        return cannot_find_course_chain_executor

    if "æµå®å¸‚" in info["topic"]["text"]:
        print("æµå®å¸‚")
        return jining_agent_executor  # TODO: Add the chain for Jinin city
    
    # ç³»ç»Ÿæ“ä½œå’¨è¯¢
    # if "å•ä½è°ƒè½¬" in info["topic"]["text"]:
    #     print("å•ä½è°ƒè½¬")
    #     return operation_chain
    # if "å­¦æ—¶ç”³æŠ¥" in info["topic"]["text"]:
    #     print("å­¦æ—¶ç”³æŠ¥")
    #     return operation_chain
    # if "å­¦æ—¶å®¡æ ¸" in info["topic"]["text"]:
    #     print("å­¦æ—¶å®¡æ ¸")
    #     return operation_chain
    # if "äººå‘˜å˜æ›´" in info["topic"]["text"]:
    #     print("äººå‘˜å˜æ›´")
    #     return operation_chain
    # if "äººå‘˜ä¿¡æ¯" in info["topic"]["text"]:
    #     print("äººå‘˜ä¿¡æ¯")
    #     return operation_chain

    # # ä¿®æ”¹ä¿¡æ¯å’¨è¯¢
    # if "ä¿®æ”¹ä¿¡æ¯" in info["topic"]["text"]:
    #     print("ä¿®æ”¹ä¿¡æ¯")
    #     return modify_info_chain
    # if "ä¸Šçº§éƒ¨é—¨æ˜¯è°" in info["topic"]["text"]:
    #     print("ä¸Šçº§éƒ¨é—¨æ˜¯è°")
    #     return modify_info_chain

    # # æ³¨å†Œé—®é¢˜å’¨è¯¢
    # if "æ³¨å†Œå’¨è¯¢" in info["topic"]["text"]:
    #     print("æ³¨å†Œå’¨è¯¢")
    #     return registration_chain
    # if "æ³¨å†Œé—®é¢˜" in info["topic"]["text"]:
    #     print("æ³¨å†Œé—®é¢˜")
    #     return registration_chain
    # if "è´¦å·å®¡æ ¸" in info["topic"]["text"]:
    #     print("è´¦å·å®¡æ ¸")
    #     return registration_chain
    # if "ç™»å½•è´¦å·ä¿¡æ¯æŸ¥è¯¢" in info["topic"]["text"]:
    #     print("ç™»å½•è´¦å·ä¿¡æ¯æŸ¥è¯¢")
    #     return registration_chain

    # æ— æ³•ç™»å½•å’¨è¯¢
    if "æ— æ³•ç™»å½•" in info["topic"]["text"]:
        print("æ— æ³•ç™»å½•")
        return login_problem_chain

    # å¿˜è®°å¯†ç å’¨è¯¢
    if "å¿˜è®°å¯†ç " in info["topic"]["text"]:
        print("å¿˜è®°å¯†ç ")
        return forgot_password_chain
    if "æ‰¾å›å¯†ç " in info["topic"]["text"]:
        print("æ‰¾å›å¯†ç ")
        return forgot_password_chain

    if "å…¶ä»–" in info["topic"]["text"]:
        print("other")
        return qa_chain_v2

    if "æ³¨å†Œ" in info["topic"]["text"]:
        print("æ³¨å†Œ")
        return qa_chain_v2
    if "å®¡æ ¸" in info["topic"]["text"]:
        print("å®¡æ ¸")
        return qa_chain_v2
    if "å­¦æ—¶å¯¹æ¥" in info["topic"]["text"]:
        print("å­¦æ—¶å¯¹æ¥")
        return qa_chain_v2
    if "ç³»ç»Ÿæ“ä½œ" in info["topic"]["text"]:
        print("ç³»ç»Ÿæ“ä½œ")
        return qa_chain_v2
    if "ä¿®æ”¹ä¿¡æ¯" in info["topic"]["text"]:
        print("ä¿®æ”¹ä¿¡æ¯")
        return qa_chain_v2
    if "å…¶ä»–" in info["topic"]["text"]:
        print("å…¶ä»–")
        return qa_chain_v2
    if "å­¦æ—¶ç”³æŠ¥" in info["topic"]["text"]:
        print("å­¦æ—¶ç”³æŠ¥")
        return qa_chain_v2
    if "å­¦æ—¶å®¡æ ¸" in info["topic"]["text"]:
        print("å­¦æ—¶å®¡æ ¸")
        return qa_chain_v2
    # if "æŸ¥è¯¢æ³¨å†ŒçŠ¶æ€" in info["topic"]["text"]:
    #     print("æŸ¥è¯¢æ³¨å†ŒçŠ¶æ€")
    #     return check_registration_status_chain
    # if "æŸ¥è¯¢ç®¡ç†å‘˜" in info["topic"]["text"]:
    #     print("æŸ¥è¯¢ç®¡ç†å‘˜")
    #     return check_registration_status_chain
    # if "æœ‰æ²¡æœ‰æ³¨å†Œ" in info["topic"]["text"]:
    #     print("æœ‰æ²¡æœ‰æ³¨å†Œ")
    #     return check_registration_status_chain

    # if "other" in info["topic"]["text"]:
    #     print("other")
    #     return other_questions_agent_executor

    # if "é€€ä¼‘äººå‘˜" in info["topic"]["text"]:
    #     print("é€€ä¼‘äººå‘˜")
    #     return other_questions_agent_executor

    # if "æµå®å¸‚" in info["topic"]["text"]:
    #     print("æµå®å¸‚")
    #     return jining_agent_executor

    print("unknown")
    return qa_chain_v2


full_chain = {
    "topic": main_question_classifier,
    "input": lambda x: x["input"],
} | RunnableLambda(main_question_classifier_and_route)

if "chat_engine" not in st.session_state.keys():  # Initialize the chat engine
    st.session_state.chat_engine = full_chain

if prompt := st.chat_input(
    "æ‚¨çš„é—®é¢˜"
):  # Prompt for user input and save to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

for message in st.session_state.messages:  # Display the prior chat messages
    with st.chat_message(message["role"]):
        st.write(message["content"])

# If last message is not from assistant, generate a new response
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨è¾“å…¥..."):
            response = st.session_state.chat_engine.invoke({"input": prompt})
            print(response)
            st.write(response["output"])
            message = {"role": "assistant", "content": response["output"]}
            st.session_state.messages.append(message)  # Add response to message history
